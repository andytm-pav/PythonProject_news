import os
import sys
import time
import requests
import feedparser
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import joblib
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import BayesianRidge
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import re
import threading
from flask import Flask, render_template_string, request
import json
import traceback
from urllib.request import urlretrieve
import zipfile
import tempfile

warnings.filterwarnings('ignore')

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ====================
RUSSIAN_SECTORS = {
    '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['GAZP', 'LKOH', 'ROSN', 'SNGS', 'TATN'],
    '–ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π': ['ALRS', 'CHMK', 'MTLR', 'TRNFP'],
    '–ë–∞–∑–æ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã': ['GMKN', 'NLMK', 'MAGN', 'PLZL', 'RUAL'],
    '–†–æ–∑–Ω–∏—á–Ω–∞—è –∏ –æ–ø—Ç–æ–≤–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è': ['FIVE', 'DSKY', 'LNTA', 'OZON'],
    '–ú–µ–¥–∏—Ü–∏–Ω–∞, —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞, –æ—Ö—Ä–∞–Ω–∞ –∑–¥–æ—Ä–æ–≤—å—è': ['POLY', 'RGSS', 'YNDX'],
    '–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π': ['GCHE', 'UPRO', 'WUSH'],
    '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏': ['MTSS', 'RTKM', 'MGNT'],
    '–•–∏–º–∏—è –∏ –Ω–µ—Ñ—Ç–µ—Ö–∏–º–∏—è': ['PHOR', 'AKRN', 'ODVA'],
    '–≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['FEES', 'HYDR', 'IRAO'],
    '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ': ['PIKK', 'LSRG', 'UNAC'],
    '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': ['AFLT', 'NMTP', 'TRMK']
}

RUSSIAN_FEEDS = {
    "–í–µ–¥–æ–º–æ—Å—Ç–∏": "https://www.vedomosti.ru/rss/news",
    "–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç": "https://www.kommersant.ru/RSS/news.xml",
    "–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å": "https://www.interfax.ru/rss.asp",
    "–¢–ê–°–°": "https://tass.ru/rss/v2.xml",
    "–õ–µ–Ω—Ç–∞.—Ä—É": "https://lenta.ru/rss/news",
    "–§–∏–Ω–∞–º": "https://www.finam.ru/analysis/conews/rsspoint/",
    "–ë–§–ú": "https://www.bfm.ru/news.rss?rubric=19",
    "–ê–ª—å—Ç–∞_–∑–∞–∫–æ–Ω": "http://www.alta.ru/rss/laws_news/",
    "–§–∏–Ω–∞–º –º–∏—Ä–æ–≤—ã—Ö": "https://www.finam.ru/international/advanced/rsspoint/",
    "–ò–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º": "https://ru.investing.com/rss/news_356.rss",
    "–ò–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º —Å—ã—Ä—å—ë": "https://ru.investing.com/rss/news_11.rss",
    "–ò–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º –≠–∫–æ–Ω–æ–º–∏–∫–∏": "https://ru.investing.com/rss/news_14.rss",
    "–ò–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º —Ñ–æ–Ω–¥–æ–≤—ã–π": "https://ru.investing.com/rss/news_25.rss",
}

# URL –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–ø—Ä–∏–º–µ—Ä)
PRETRAINED_MODEL_URLS = {
    'base_model': 'https://example.com/models/russian_stocks_base_model.joblib',
    'advanced_model': 'https://example.com/models/russian_stocks_advanced_model.joblib'
}


# ==================== –ö–õ–ê–°–° –î–õ–Ø –°–ë–û–†–ê –ù–û–í–û–°–¢–ï–ô ====================
class NewsCollector:
    def __init__(self):
        self.feeds = RUSSIAN_FEEDS

    def fetch_all_news(self, max_items_per_feed=20):
        """–°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –≤—Å–µ—Ö RSS-–ª–µ–Ω—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        all_news = []

        for source, url in self.feeds.items():
            try:
                print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {source}...")
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                }

                feed = feedparser.parse(url)
                time.sleep(1)

                if not feed.entries:
                    print(f"  –ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {source}")
                    continue

                items_added = 0
                for entry in feed.entries[:max_items_per_feed]:
                    try:
                        title = getattr(entry, 'title', '').strip()
                        if not title:
                            continue

                        published = getattr(entry, 'published', '')
                        if not published:
                            published = getattr(entry, 'updated', datetime.now().isoformat())

                        news_item = {
                            'source': source,
                            'title': title,
                            'link': getattr(entry, 'link', ''),
                            'published': published,
                            'published_parsed': getattr(entry, 'published_parsed', None),
                            'summary': getattr(entry, 'summary', '')[:500],
                            'timestamp': datetime.now()
                        }

                        all_news.append(news_item)
                        items_added += 1

                    except Exception as e:
                        continue

                print(f"  –î–æ–±–∞–≤–ª–µ–Ω–æ {items_added} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {source}")

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ {source}: {e}")
                continue

        news_df = pd.DataFrame(all_news)
        if not news_df.empty:
            news_df = news_df.drop_duplicates(subset=['title'])
            news_df = news_df.reset_index(drop=True)

        print(f"–í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_df)}")
        return news_df


# ==================== –ö–õ–ê–°–° –î–õ–Ø –ü–û–õ–£–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–• –û –ê–ö–¶–ò–Ø–• ====================
class StockDataCollector:
    def __init__(self):
        self.base_url = "https://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/securities"

    def get_stock_prices(self, tickers, days=30):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ü–∏—è—Ö —Å –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏"""
        stock_data = {}
        successful_downloads = 0

        for ticker in tickers:
            try:
                url = f"{self.base_url}/{ticker}/candles.json"
                from_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y-%m-%d')

                params = {
                    'from': from_date,
                    'till': datetime.now().strftime('%Y-%m-%d'),
                    'interval': 24
                }

                response = requests.get(url, params=params, timeout=10)

                if response.status_code == 200:
                    data = response.json()
                    candles = data.get('candles', {}).get('data', [])

                    if candles:
                        dates = []
                        prices = []

                        for candle in candles:
                            date_str = candle[6]
                            close_price = candle[5]

                            if date_str and close_price:
                                dates.append(date_str)
                                prices.append(close_price)

                        if dates and prices:
                            series = pd.Series(prices, index=dates)
                            stock_data[ticker] = series
                            successful_downloads += 1

                time.sleep(0.5)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {ticker}: {e}")
                continue

        print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {successful_downloads} —Ç–∏–∫–µ—Ä–æ–≤")

        if stock_data:
            prices_df = pd.DataFrame(stock_data)
            prices_df = prices_df.ffill().bfill()
            return prices_df
        else:
            return self.create_test_data(tickers, days)

    def create_test_data(self, tickers, days):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ"""
        print("–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        dates = pd.date_range(end=datetime.now(), periods=days, freq='D')

        base_prices = {
            'SBER': 250, 'GAZP': 160, 'LKOH': 5800, 'GMKN': 25000, 'NLMK': 180,
            'MTSS': 270, 'ROSN': 420, 'TATN': 380, 'VTBR': 0.03, 'MOEX': 150,
            'ALRS': 450, 'CHMK': 50, 'MTLR': 700, 'TRNFP': 150000,
            'FIVE': 2100, 'DSKY': 600, 'LNTA': 2000, 'OZON': 2200,
            'POLY': 700, 'RGSS': 300, 'YNDX': 2900,
            'GCHE': 1500, 'UPRO': 20, 'WUSH': 5,
            'RTKM': 70, 'MGNT': 4500,
            'PHOR': 8000, 'AKRN': 6500, 'ODVA': 200,
            'FEES': 20, 'HYDR': 1, 'IRAO': 3,
            'PIKK': 1100, 'LSRG': 800, 'UNAC': 500,
            'AFLT': 40, 'NMTP': 300, 'TRMK': 1500
        }

        prices_df = pd.DataFrame(index=dates)
        np.random.seed(42)

        for ticker in tickers:
            base_price = base_prices.get(ticker, 100)
            returns = np.random.normal(0.001, 0.02, days)

            prices = [base_price]
            for ret in returns[1:]:
                new_price = prices[-1] * (1 + ret)
                prices.append(max(new_price, 0.01))

            prices_df[ticker] = prices

        return prices_df


# ==================== –ö–õ–ê–°–° –ê–ù–ê–õ–ò–ó–ê –ù–û–í–û–°–¢–ï–ô ====================
class NewsAnalyzer:
    def __init__(self):
        self.sector_keywords = self._build_sector_keywords()
        self.sentiment_words = self._build_sentiment_lexicon()

    def _build_sector_keywords(self):
        return {
            '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '–Ω–µ—Ñ—Ç–µ–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫', '–Ω–µ—Ñ—Ç—è–Ω–æ–π', '–≥–∞–∑–æ–≤—ã–π', '–Ω–µ—Ñ—Ç–µ–¥–æ–±—ã—á–∞',
                           '–º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–µ'],
            '–ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π': ['–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç', '–∑–∞–≤–æ–¥', '–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤', '–∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω', '–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω'],
            '–ë–∞–∑–æ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã': ['–º–µ—Ç–∞–ª–ª', '—Å—Ç–∞–ª—å', '–Ω–∏–∫–µ–ª—å', '–∞–ª—é–º–∏–Ω', '–º–µ–¥—å', '—Ä—É–¥', '–≥–æ—Ä–Ω–æ–¥–æ–±—ã–≤–∞—é—â'],
            '–†–æ–∑–Ω–∏—á–Ω–∞—è –∏ –æ–ø—Ç–æ–≤–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è': ['—Ä–∏—Ç–µ–π–ª', '–º–∞–≥–∞–∑–∏–Ω', '—Ç–æ—Ä–≥–æ–≤–ª—è', '—Ä–æ–∑–Ω–∏—á–Ω', '–ø–æ–∫—É–ø', '–ø—Ä–æ–¥–∞–∂', '—Ç–æ–≤–∞—Ä'],
            '–ú–µ–¥–∏—Ü–∏–Ω–∞, —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞, –æ—Ö—Ä–∞–Ω–∞ –∑–¥–æ—Ä–æ–≤—å—è': ['—Ñ–∞—Ä–º–∞', '–º–µ–¥–∏—Ü–∏–Ω', '–ª–µ–∫–∞—Ä—Å—Ç–≤', '–ø—Ä–µ–ø–∞—Ä–∞—Ç', '–≤–∏—Ç–∞–º–∏–Ω',
                                                        '–∑–¥–æ—Ä–æ–≤—å–µ', '–±–æ–ª—å–Ω–∏'],
            '–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π': ['–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å', '—Å–ø—Ä–æ—Å', '—Ä–æ–∑–Ω–∏—á–Ω', '–ø–æ–∫—É–ø', '—Ç–æ–≤–∞—Ä'],
            '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏': ['—Å–≤—è–∑—å', '—Ç–µ–ª–µ–∫–æ–º', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç', '–º–æ–±–∏–ª—å–Ω', '—Ç–∞—Ä–∏—Ñ', '–∞–±–æ–Ω–µ–Ω—Ç'],
            '–•–∏–º–∏—è –∏ –Ω–µ—Ñ—Ç–µ—Ö–∏–º–∏—è': ['—Ö–∏–º–∏—è', '—É–¥–æ–±—Ä–µ–Ω', '–Ω–µ—Ñ—Ç–µ—Ö–∏–º', '–ø–æ–ª–∏–º–µ—Ä', '–ø–ª–∞—Å—Ç–∏–∫'],
            '–≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['—ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥', '—ç–Ω–µ—Ä–≥–æ—Å–±—ã—Ç', '—ç–ª–µ–∫—Ç—Ä–æ—Å–µ—Ç', '—ç–ª–µ–∫—Ç—Ä–æ—Å—Ç–∞–Ω—Ü'],
            '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ': ['—Å—Ç—Ä–æ–∏—Ç–µ–ª—å', '–¥–µ–≤–µ–ª–æ–ø–µ—Ä', '–Ω–µ–¥–≤–∏–∂', '–∂–∏–ª—å–µ', '–∫–≤–∞—Ä—Ç–∏—Ä'],
            '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': ['–∞–≤–∏–∞', '—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–ø–æ—Ä—Ç', '–∞—ç—Ä–æ–ø–æ—Ä—Ç', '–≥—Ä—É–∑', '–ª–æ–≥–∏—Å—Ç–∏–∫']
        }

    def _build_sentiment_lexicon(self):
        return {
            'positive': ['—Ä–æ—Å—Ç', '–≤—ã—Ä–æ—Å', '—É–≤–µ–ª–∏—á–∏–ª', '–ø—Ä–∏–±—ã–ª—å', '–¥–æ—Ö–æ–¥', '—É—Å–ø–µ—Ö', '—Ä–µ–∫–æ—Ä–¥', '—É–ª—É—á—à–µ–Ω–∏–µ', '–ø–æ–∑–∏—Ç–∏–≤'],
            'negative': ['–ø–∞–¥–µ–Ω–∏–µ', '—Å–Ω–∏–∂–µ–Ω', '—É–ø–∞–ª', '—Å–æ–∫—Ä–∞—â–µ–Ω', '—É–±—ã—Ç–æ–∫', '–ø—Ä–æ–±–ª–µ–º', '–∫—Ä–∏–∑–∏—Å', '—Å–ª–∞–±', '–Ω–µ–≥–∞—Ç–∏–≤'],
            'intensifiers': ['–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω', '—Ä–µ–∑–∫', '—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω', '–∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω', '–º–∞—Å—à—Ç–∞–±–Ω']
        }

    def analyze_sentiment(self, text):
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞"""
        if not isinstance(text, str):
            return 0.0

        text_lower = text.lower()
        positive_score = 0
        negative_score = 0

        for word in self.sentiment_words['positive']:
            if word in text_lower:
                positive_score += 1
                for intensifier in self.sentiment_words['intensifiers']:
                    if f"{intensifier} {word}" in text_lower:
                        positive_score += 0.5
                        break

        for word in self.sentiment_words['negative']:
            if word in text_lower:
                negative_score += 1
                for intensifier in self.sentiment_words['intensifiers']:
                    if f"{intensifier} {word}" in text_lower:
                        negative_score += 0.5
                        break

        total_score = positive_score - negative_score
        return max(-1.0, min(1.0, total_score * 0.2))

    def identify_sectors(self, text):
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–µ–∫—Ç–æ—Ä–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not isinstance(text, str):
            return []

        text_lower = text.lower()
        sectors_found = []

        for sector, keywords in self.sector_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    sectors_found.append(sector)
                    break

        return sectors_found if sectors_found else ['–û–±—â–∏–µ']

    def predict_sector_sentiment(self, news_df):
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        sector_sentiments = {sector: [] for sector in RUSSIAN_SECTORS.keys()}

        for _, news in news_df.iterrows():
            title = news['title']
            summary = news.get('summary', '')
            text = f"{title}. {summary}"

            sentiment = self.analyze_sentiment(text)
            sectors = self.identify_sectors(text)

            for sector in sectors:
                if sector in sector_sentiments:
                    sector_sentiments[sector].append(sentiment)

        recommendations = {}
        for sector, sentiments in sector_sentiments.items():
            if sentiments:
                avg_sentiment = np.mean(sentiments)
                recommendation = int(round(avg_sentiment * 5))
                recommendation = max(-5, min(5, recommendation))
            else:
                recommendation = 0

            recommendations[sector] = recommendation

        return recommendations


# ==================== –£–õ–£–ß–®–ï–ù–ù–´–ô –ö–õ–ê–°–° –ò–ò –ú–û–î–ï–õ–ò ====================
class EnhancedStockAIModel:
    def __init__(self, model_path='enhanced_stock_ai_model.joblib'):
        self.model_path = model_path
        self.model = None
        self.probabilistic_model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.training_history = []
        self.model_metadata = {}

        # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        self._initialize_model_with_fallback()

    def _initialize_model_with_fallback(self):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å —Å–∏—Å—Ç–µ–º–æ–π fallback"""
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–ò –º–æ–¥–µ–ª–µ–π...")

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
        if self._try_load_existing_model():
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞")
            return

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        if self._try_download_pretrained_model():
            print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
            return

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        print("üìù –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
        self._create_new_models()
        print("‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å")

    def _try_load_existing_model(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏"""
        try:
            if not os.path.exists(self.model_path):
                print("üìù –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False

            print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}")
            model_data = joblib.load(self.model_path)

            if isinstance(model_data, dict):
                return self._load_from_dict(model_data)
            else:
                return self._load_old_format(model_data)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def _try_download_pretrained_model(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            # –í —Ä–µ–∞–ª—å–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏ —ç—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –º–æ–¥–µ–ª–∏ —Å HuggingFace –∏–ª–∏ –¥—Ä—É–≥–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            pretrained_url = PRETRAINED_MODEL_URLS.get('base_model')

            if not pretrained_url:
                print("‚ÑπÔ∏è URL –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–µ —É–∫–∞–∑–∞–Ω—ã")
                return False

            print(f"üåê –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            with tempfile.NamedTemporaryFile(delete=False, suffix='.joblib') as tmp_file:
                temp_path = tmp_file.name

            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                urlretrieve(pretrained_url, temp_path)

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
                model_data = joblib.load(temp_path)

                if isinstance(model_data, dict):
                    success = self._load_from_dict(model_data)
                    if success:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                        self._save_models()
                        print("üíæ –ü—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ")
                    return success

            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                if os.path.exists(temp_path):
                    os.unlink(temp_path)

            return False

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return False

    def _load_from_dict(self, model_data):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Å–ª–æ–≤–∞—Ä—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            required_keys = ['main_model', 'probabilistic_model', 'scaler']
            if not all(key in model_data for key in required_keys):
                print("‚ùå –í —Ñ–∞–π–ª–µ –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã")
                return False

            self.model = model_data['main_model']
            self.probabilistic_model = model_data['probabilistic_model']
            self.scaler = model_data['scaler']
            self.is_trained = model_data.get('is_trained', True)
            self.training_history = model_data.get('training_history', [])
            self.model_metadata = model_data.get('model_metadata', {})

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
            if self.model is None or self.probabilistic_model is None:
                print("‚ùå –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∞–≤–Ω—ã None")
                return False

            print(f"üìä –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(self.training_history)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫, "
                  f"{self.model_metadata.get('total_training_samples', 0)} samples")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è: {e}")
            return False

    def _load_old_format(self, model_data):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –º–æ–¥–µ–ª–∏"""
        try:
            if isinstance(model_data, (list, tuple)) and len(model_data) >= 2:
                self.model = model_data[0]
                self.probabilistic_model = model_data[1]
                self.is_trained = True
                return True
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")
            return False

    def _create_new_models(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        try:
            # RandomForest —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º warm_start –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                warm_start=True  # –í–∞–∂–Ω–æ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è!
            )

            # BayesianRidge –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            self.probabilistic_model = BayesianRidge(
                n_iter=200,
                tol=1e-3
            )

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º scaler
            self.scaler = StandardScaler()

            self.is_trained = False
            self.model_metadata = {
                'creation_date': datetime.now().isoformat(),
                'total_training_samples': 0,
                'training_sessions': 0,
                'last_training': None,
                'model_type': 'EnhancedStockAIModel_v5',
                'supports_incremental_learning': True
            }

            return True

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–µ–π—à–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            self.model = RandomForestRegressor(n_estimators=10, random_state=42)
            self.probabilistic_model = BayesianRidge()
            self.is_trained = False
            return False

    def train_models(self, prices_df, news_sentiment_by_date, incremental=True):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–æ–æ–±—É—á–µ–Ω–∏—è"""
        try:
            print("üîÑ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π
            if self.model is None or self.probabilistic_model is None:
                print("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ...")
                self._create_new_models()

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            X, y = self.prepare_training_data(prices_df, news_sentiment_by_date)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
            if not self._validate_training_data(X, y):
                print("‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return False

            print(f"üéØ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(X)} –ø—Ä–∏–º–µ—Ä–∞—Ö...")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —É—á–µ—Ç–æ–º –¥–æ–æ–±—É—á–µ–Ω–∏—è
            try:
                if self.is_trained and incremental and hasattr(self.scaler, 'n_features_in_'):
                    # –î–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è - partial_fit –∏–ª–∏ transform
                    if hasattr(self.scaler, 'partial_fit'):
                        self.scaler.partial_fit(X)
                    X_processed = self.scaler.transform(X)
                else:
                    # –ü–µ—Ä–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –ø–æ–ª–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
                    X_processed = self.scaler.fit_transform(X)
            except Exception as scale_error:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {scale_error}, –ø—Ä–∏–º–µ–Ω—è–µ–º fit_transform")
                X_processed = self.scaler.fit_transform(X)

            # –û–ë–£–ß–ï–ù–ò–ï –° –ü–û–î–î–ï–†–ñ–ö–û–ô –î–û–û–ë–£–ß–ï–ù–ò–Ø
            if self.is_trained and incremental:
                print("üìö –î–æ–æ–±—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏...")
                # –î–ª—è RandomForest —Å warm_start=True –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å n_estimators
                if hasattr(self.model, 'warm_start') and self.model.warm_start:
                    current_estimators = self.model.n_estimators
                    self.model.n_estimators = current_estimators + 50
                    self.model.fit(X_processed, y)
                else:
                    self.model.fit(X_processed, y)

                # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å —Ç–∞–∫–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–æ–æ–±—É—á–µ–Ω–∏–µ
                self.probabilistic_model.fit(X_processed, y)
            else:
                # –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
                print("üéì –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
                self.model.fit(X_processed, y)
                self.probabilistic_model.fit(X_processed, y)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.is_trained = True
            training_type = "incremental" if (self.is_trained and incremental) else "full"
            self._update_training_metadata(len(X), training_type)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏
            self._save_models()

            print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            traceback.print_exc()
            return False

    def _update_training_metadata(self, new_samples_count, training_type):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        current_total = self.model_metadata.get('total_training_samples', 0)
        self.model_metadata['total_training_samples'] = current_total + new_samples_count
        self.model_metadata['training_sessions'] = self.model_metadata.get('training_sessions', 0) + 1
        self.model_metadata['last_training'] = datetime.now().isoformat()
        self.model_metadata['last_training_type'] = training_type

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫
        self.training_history.append({
            'timestamp': datetime.now().isoformat(),
            'samples': new_samples_count,
            'total_samples': self.model_metadata['total_training_samples'],
            'type': training_type
        })

    def _validate_training_data(self, X, y):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if X is None or y is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ä–∞–≤–Ω—ã None")
            return False

        if len(X) == 0 or len(y) == 0:
            print("‚ùå –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False

        if len(X) != len(y):
            print("‚ùå –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ X –∏ y")
            return False

        return True

    def _save_models(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
        try:
            if self.model is None or self.probabilistic_model is None:
                print("‚ö†Ô∏è –ù–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å: –º–æ–¥–µ–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
                return False

            models_to_save = {
                'main_model': self.model,
                'probabilistic_model': self.probabilistic_model,
                'scaler': self.scaler,
                'is_trained': self.is_trained,
                'training_history': self.training_history,
                'model_metadata': self.model_metadata
            }

            joblib.dump(models_to_save, self.model_path)
            print(f"üíæ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.model_path}")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            return False

    def create_advanced_features(self, prices_df, news_sentiment):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        features = {}

        if prices_df.empty:
            print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return features

        for ticker in prices_df.columns:
            try:
                if ticker not in prices_df:
                    continue

                price_series = prices_df[ticker].dropna()
                if len(price_series) < 30:
                    continue

                # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                returns = price_series.pct_change().dropna()
                if len(returns) < 15:
                    continue

                # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                volatility = returns.std()
                current_price = price_series.iloc[-1]
                ma_short = price_series.rolling(window=5).mean().iloc[-1]
                ma_long = price_series.rolling(window=20).mean().iloc[-1]

                features[ticker] = {
                    'volatility': float(volatility) if not pd.isna(volatility) else 0.02,
                    'price_ratio': float(current_price / ma_long) if ma_long != 0 else 1.0,
                    'ma_ratio': float(ma_short / ma_long) if ma_long != 0 else 1.0,
                    'sector_sentiment': float(news_sentiment.get(self.get_sector_for_ticker(ticker), 0))
                }

            except Exception as e:
                continue

        return features

    def get_sector_for_ticker(self, ticker):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Ç–∏–∫–µ—Ä–∞"""
        for sector, tickers in RUSSIAN_SECTORS.items():
            if ticker in tickers:
                return sector
        return '–û–±—â–∏–µ'

    def prepare_training_data(self, prices_df, news_sentiment_by_date, forecast_days=5):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        X, y = [], []

        if prices_df.empty:
            return np.array([]), np.array([])

        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        current_sentiment = {}
        if news_sentiment_by_date:
            latest_date = max(news_sentiment_by_date.keys())
            current_sentiment = news_sentiment_by_date[latest_date]

        features_dict = self.create_advanced_features(prices_df, current_sentiment)

        for ticker, features in features_dict.items():
            if features and len(features) > 0:
                feature_vector = list(features.values())
                # –ü—Ä–æ—Å—Ç–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                target = np.random.uniform(-0.1, 0.1)  # –ó–∞–º–µ–Ω–∏—Ç–µ —Ä–µ–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
                X.append(feature_vector)
                y.append(target)

        if len(X) > 0:
            return np.array(X), np.array(y)
        else:
            return np.array([]), np.array([])

    def predict_with_confidence(self, current_features):
        """–ü—Ä–æ–≥–Ω–æ–∑ —Å –æ—Ü–µ–Ω–∫–æ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏"""
        if not self.is_trained or self.model is None:
            return 0.0, 0.0

        try:
            if isinstance(current_features, dict):
                feature_vector = list(current_features.values())
            else:
                feature_vector = current_features

            if len(feature_vector) == 0:
                return 0.0, 0.0

            features_array = np.array(feature_vector).reshape(1, -1)
            features_array = self.scaler.transform(features_array)

            main_pred = self.model.predict(features_array)[0]
            probabilistic_pred, probabilistic_std = self.probabilistic_model.predict(features_array, return_std=True)

            combined_pred = 0.7 * main_pred + 0.3 * probabilistic_pred
            confidence = max(0.0, min(1.0, 1.0 - probabilistic_std[0]))

            return float(combined_pred), float(confidence)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return 0.0, 0.0

    def get_training_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ –º–æ–¥–µ–ª–∏"""
        if not self.training_history:
            return "–ú–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –æ–±—É—á–∞–ª–∞—Å—å"

        latest = self.training_history[-1]
        return {
            'last_training': latest['timestamp'],
            'samples': latest['total_samples'],
            'total_trainings': len(self.training_history),
            'model_metadata': self.model_metadata
        }

    def get_model_status(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏"""
        return {
            'is_trained': self.is_trained,
            'model_initialized': self.model is not None,
            'training_sessions': len(self.training_history),
            'total_samples': self.model_metadata.get('total_training_samples', 0),
            'supports_incremental': self.model_metadata.get('supports_incremental_learning', False)
        }


# ==================== –ö–õ–ê–°–° –í–ò–†–¢–£–ê–õ–¨–ù–û–ì–û –ü–û–†–¢–§–ï–õ–Ø ====================
class VirtualPortfolio:
    def __init__(self, initial_cash=10000):
        self.initial_cash = initial_cash
        self.cash = initial_cash
        self.positions = {}
        self.transaction_history = []
        self.portfolio_file = 'portfolio.json'
        self.load_portfolio()

    def load_portfolio(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è –∏–∑ —Ñ–∞–π–ª–∞"""
        if os.path.exists(self.portfolio_file):
            try:
                with open(self.portfolio_file, 'r') as f:
                    data = json.load(f)
                    self.cash = data.get('cash', self.initial_cash)
                    self.positions = data.get('positions', {})
                print("‚úÖ –ü–æ—Ä—Ç—Ñ–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}")

    def save_portfolio(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è –≤ —Ñ–∞–π–ª"""
        try:
            data = {
                'cash': self.cash,
                'positions': self.positions,
                'last_updated': datetime.now().isoformat()
            }
            with open(self.portfolio_file, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}")

    def execute_trade(self, sector, ticker, action, price, quantity):
        """–ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–¥–µ–ª–∫–∏"""
        try:
            cost = price * quantity

            if action == 'BUY':
                if self.cash >= cost:
                    self.cash -= cost
                    if ticker in self.positions:
                        self.positions[ticker]['quantity'] += quantity
                        self.positions[ticker]['avg_price'] = (
                                                                      self.positions[ticker]['avg_price'] + price) / 2
                    else:
                        self.positions[ticker] = {
                            'quantity': quantity,
                            'avg_price': price,
                            'sector': sector
                        }

                    self.transaction_history.append({
                        'timestamp': datetime.now(),
                        'sector': sector,
                        'ticker': ticker,
                        'action': action,
                        'quantity': quantity,
                        'price': price,
                        'total': cost
                    })
                    self.save_portfolio()
                    return True

            elif action == 'SELL':
                if ticker in self.positions and self.positions[ticker]['quantity'] >= quantity:
                    self.cash += cost
                    self.positions[ticker]['quantity'] -= quantity

                    if self.positions[ticker]['quantity'] == 0:
                        del self.positions[ticker]

                    self.transaction_history.append({
                        'timestamp': datetime.now(),
                        'sector': sector,
                        'ticker': ticker,
                        'action': action,
                        'quantity': quantity,
                        'price': price,
                        'total': cost
                    })
                    self.save_portfolio()
                    return True

            return False

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è —Å–¥–µ–ª–∫–∏: {e}")
            return False

    def get_portfolio_value(self, current_prices):
        """–†–∞—Å—á–µ—Ç —Ç–µ–∫—É—â–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        total_value = self.cash

        for ticker, position in self.positions.items():
            if ticker in current_prices:
                total_value += current_prices[ticker] * position['quantity']

        return total_value


# ==================== –ö–õ–ê–°–° –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ô –†–ï–ë–ê–õ–ê–ù–°–ò–†–û–í–ö–ò ====================
class PortfolioRebalancer:
    def __init__(self, portfolio, threshold=0.05, strategy='calendar_absolute'):
        self.portfolio = portfolio
        self.threshold = threshold
        self.strategy = strategy
        self.last_rebalance_date = None
        self.target_weights = self._initialize_target_weights()

    def _initialize_target_weights(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–ª–µ–≤—ã—Ö –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        sector_weights = {}
        sectors_count = len(RUSSIAN_SECTORS)

        for sector in RUSSIAN_SECTORS.keys():
            sector_weights[sector] = 1.0 / sectors_count

        return sector_weights

    def calculate_current_weights(self, current_prices):
        """–†–∞—Å—á–µ—Ç —Ç–µ–∫—É—â–∏—Ö –≤–µ—Å–æ–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        total_value = self.portfolio.get_portfolio_value(current_prices)
        if total_value == 0:
            return {}

        current_weights = {}
        sector_values = {sector: 0 for sector in RUSSIAN_SECTORS.keys()}

        for ticker, position in self.portfolio.positions.items():
            if ticker in current_prices:
                position_value = current_prices[ticker] * position['quantity']
                sector = position.get('sector', '–û–±—â–∏–µ')
                if sector in sector_values:
                    sector_values[sector] += position_value

        for sector, value in sector_values.items():
            current_weights[sector] = value / total_value

        return current_weights

    def needs_rebalancing(self, current_weights, current_date):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏"""

        if self.strategy.startswith('calendar'):
            if self.last_rebalance_date is None:
                return True

            days_since_rebalance = (current_date - self.last_rebalance_date).days

            if 'month' in self.strategy and days_since_rebalance >= 30:
                return True
            elif 'quarter' in self.strategy and days_since_rebalance >= 90:
                return True
            elif 'year' in self.strategy and days_since_rebalance >= 365:
                return True

            if 'absolute' in self.strategy or 'relative' in self.strategy:
                return self._check_threshold_deviation(current_weights)

        elif self.strategy == 'threshold':
            return self._check_threshold_deviation(current_weights)

        return False

    def _check_threshold_deviation(self, current_weights):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Ü–µ–ª–µ–≤—ã—Ö –≤–µ—Å–æ–≤"""
        for sector, target_weight in self.target_weights.items():
            current_weight = current_weights.get(sector, 0)

            if self.strategy.endswith('absolute'):
                deviation = abs(current_weight - target_weight)
                if deviation > self.threshold:
                    return True

            elif self.strategy.endswith('relative'):
                if target_weight > 0:
                    relative_deviation = abs(current_weight - target_weight) / target_weight
                    if relative_deviation > self.threshold:
                        return True

        return False

    def generate_rebalancing_trades(self, current_weights, current_prices, ai_recommendations):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–¥–µ–ª–æ–∫ –¥–ª—è —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        trades = []
        total_value = self.portfolio.get_portfolio_value(current_prices)

        if total_value == 0:
            return trades

        adjusted_target_weights = self._adjust_weights_with_ai(current_weights, ai_recommendations)

        for sector, target_weight in adjusted_target_weights.items():
            current_weight = current_weights.get(sector, 0)
            deviation = current_weight - target_weight

            if abs(deviation) > self.threshold:
                sector_tickers = RUSSIAN_SECTORS.get(sector, [])

                if deviation > 0 and sector_tickers:
                    sell_value = total_value * deviation * 0.8
                    trades.extend(self._generate_sell_trades(sector, sector_tickers, sell_value, current_prices))

                elif deviation < 0 and sector_tickers:
                    buy_value = total_value * abs(deviation) * 0.8
                    trades.extend(self._generate_buy_trades(sector, sector_tickers, buy_value, current_prices,
                                                            ai_recommendations.get(sector, 0)))

        return trades

    def _adjust_weights_with_ai(self, current_weights, ai_recommendations):
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        adjusted_weights = self.target_weights.copy()

        for sector, recommendation in ai_recommendations.items():
            if sector in adjusted_weights:
                adjustment_factor = 1.0 + (recommendation * 0.06)
                adjusted_weights[sector] *= adjustment_factor

        total_weight = sum(adjusted_weights.values())
        if total_weight > 0:
            for sector in adjusted_weights:
                adjusted_weights[sector] /= total_weight

        return adjusted_weights

    def _generate_buy_trades(self, sector, tickers, total_buy_value, current_prices, sector_recommendation):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–¥–µ–ª–æ–∫ –Ω–∞ –ø–æ–∫—É–ø–∫—É"""
        trades = []

        if total_buy_value <= 0 or not tickers:
            return trades

        buy_per_ticker = total_buy_value / len(tickers)

        for ticker in tickers:
            if ticker in current_prices and current_prices[ticker] > 0:
                quantity = int(buy_per_ticker / current_prices[ticker])
                if quantity > 0:
                    trades.append({
                        'sector': sector,
                        'ticker': ticker,
                        'action': 'BUY',
                        'quantity': quantity,
                        'price': current_prices[ticker],
                        'reason': f'–†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Å–µ–∫—Ç–æ—Ä–∞ {sector} (AI —Ä–µ–∫–æ–º: {sector_recommendation})'
                    })

        return trades

    def _generate_sell_trades(self, sector, tickers, total_sell_value, current_prices):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–¥–µ–ª–æ–∫ –Ω–∞ –ø—Ä–æ–¥–∞–∂—É"""
        trades = []

        if total_sell_value <= 0 or not tickers:
            return trades

        for ticker in tickers:
            if ticker in self.portfolio.positions and ticker in current_prices:
                position = self.portfolio.positions[ticker]
                position_value = position['quantity'] * current_prices[ticker]
                portfolio_value = self.portfolio.get_portfolio_value(current_prices)

                if portfolio_value > 0:
                    position_weight = position_value / portfolio_value
                    sell_quantity = int(position['quantity'] * (total_sell_value / portfolio_value) / position_weight)

                    if sell_quantity > 0:
                        trades.append({
                            'sector': sector,
                            'ticker': ticker,
                            'action': 'SELL',
                            'quantity': min(sell_quantity, position['quantity']),
                            'price': current_prices[ticker],
                            'reason': f'–†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Å–µ–∫—Ç–æ—Ä–∞ {sector}'
                        })

        return trades

    def execute_rebalancing(self, current_prices, ai_recommendations):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        current_weights = self.calculate_current_weights(current_prices)
        current_date = datetime.now()

        if self.needs_rebalancing(current_weights, current_date):
            print("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è...")

            trades = self.generate_rebalancing_trades(current_weights, current_prices, ai_recommendations)

            executed_trades = []
            for trade in trades:
                success = self.portfolio.execute_trade(
                    trade['sector'],
                    trade['ticker'],
                    trade['action'],
                    trade['price'],
                    trade['quantity']
                )

                if success:
                    executed_trades.append(trade)
                    print(f"  {trade['action']} {trade['ticker']} {trade['quantity']} —à—Ç.")

            self.last_rebalance_date = current_date
            print(f"‚úÖ –†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Å–ø–æ–ª–Ω–µ–Ω–æ —Å–¥–µ–ª–æ–∫: {len(executed_trades)}")

            return executed_trades

        return []


# ==================== –í–ï–ë-–ò–ù–¢–ï–†–§–ï–ô–° ====================
app = Flask(__name__)


class WebInterface:
    def __init__(self):
        self.current_recommendations = {}
        self.news_items = []
        self.portfolio_value = 0
        self.is_running = True

    def update_data(self, recommendations, news_df, portfolio_value):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        self.current_recommendations = recommendations
        self.news_items = news_df.to_dict('records') if not news_df.empty else []
        self.portfolio_value = portfolio_value

    def get_html_template(self):
        """HTML —à–∞–±–ª–æ–Ω –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        return '''
        <!DOCTYPE html>
        <html>
        <head>
            <title>–ê–Ω–∞–ª–∏–∑ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π —Å –ò–ò</title>
            <meta charset="UTF-8">
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
                .container { max-width: 1200px; margin: 0 auto; }
                .header { background: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; }
                .recommendations { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 15px; margin-bottom: 20px; }
                .sector-card { background: white; padding: 15px; border-radius: 8px; border-left: 5px solid #ddd; }
                .positive { border-left-color: #4CAF50 !important; background: #f1f8e9 !important; }
                .negative { border-left-color: #f44336 !important; background: #ffebee !important; }
                .news-item { background: white; padding: 15px; margin-bottom: 10px; border-radius: 8px; border-left: 4px solid #2196F3; }
                .news-new { background: #e3f2fd !important; border-left-color: #FF9800 !important; }
                .controls { background: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; }
                .btn { padding: 10px 20px; background: #2196F3; color: white; border: none; border-radius: 5px; cursor: pointer; }
                .btn-stop { background: #f44336; }
                .portfolio { background: white; padding: 20px; border-radius: 10px; }
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ü§ñ –ê–Ω–∞–ª–∏–∑ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π —Å –ò–ò</h1>
                    <p>–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {{ current_time }}</p>
                </div>

                <div class="controls">
                    <button class="btn" onclick="location.reload()">–û–±–Ω–æ–≤–∏—Ç—å</button>
                    <button class="btn btn-stop" onclick="stopProgram()">–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—É</button>
                </div>

                <div class="portfolio">
                    <h2>üíº –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å</h2>
                    <p><strong>–¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å:</strong> {{ "‚ÇΩ{:,.2f}".format(portfolio_value) }}</p>
                </div>

                <h2>üìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º</h2>
                <div class="recommendations">
                    {% for sector, rec in recommendations.items() %}
                    <div class="sector-card {{ 'positive' if rec > 0 else 'negative' if rec < 0 else '' }}">
                        <h3>{{ sector }}</h3>
                        <p><strong>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:</strong> {{ rec }}/5</p>
                        <p><em>{{ get_recommendation_text(rec) }}</em></p>
                    </div>
                    {% endfor %}
                </div>

                <h2>üì∞ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏</h2>
                <div id="news">
                    {% for news in news_items %}
                    <div class="news-item {{ 'news-new' if is_new_news(news.timestamp) else '' }}">
                        <h4>{{ news.title }}</h4>
                        <p><strong>–ò—Å—Ç–æ—á–Ω–∏–∫:</strong> {{ news.source }} | <strong>–î–∞—Ç–∞:</strong> {{ news.published }}</p>
                        <p>{{ news.summary[:200] }}{% if news.summary|length > 200 %}...{% endif %}</p>
                    </div>
                    {% endfor %}
                </div>
            </div>

            <script>
                function stopProgram() {
                    fetch('/stop', { method: 'POST' })
                        .then(response => response.json())
                        .then(data => {
                            if (data.success) {
                                alert('–ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...');
                            }
                        });
                }

                // –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                setTimeout(() => location.reload(), 300000);
            </script>
        </body>
        </html>
        '''

    def run_server(self, host='0.0.0.0', port=5000):
        """–ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞"""

        @app.route('/')
        def index():
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            def get_recommendation_text(rec):
                if rec == 5:
                    return '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ–∫—É–ø–∫–∞'
                elif rec >= 3:
                    return '–°–∏–ª—å–Ω–∞—è –ø–æ–∫—É–ø–∫–∞'
                elif rec >= 1:
                    return '–£–º–µ—Ä–µ–Ω–Ω–∞—è –ø–æ–∫—É–ø–∫–∞'
                elif rec == 0:
                    return '–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ'
                elif rec >= -2:
                    return '–£–º–µ—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞'
                elif rec >= -4:
                    return '–°–∏–ª—å–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞'
                else:
                    return '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–¥–∞–∂–∞'

            def is_new_news(timestamp):
                if isinstance(timestamp, str):
                    try:
                        news_time = datetime.fromisoformat(timestamp.replace('Z', ''))
                    except:
                        return False
                else:
                    news_time = timestamp
                return (datetime.now() - news_time).total_seconds() < 3600

            template = self.get_html_template()
            return render_template_string(
                template,
                recommendations=self.current_recommendations,
                news_items=self.news_items[-20:],
                current_time=current_time,
                portfolio_value=self.portfolio_value,
                get_recommendation_text=get_recommendation_text,
                is_new_news=is_new_news
            )

        @app.route('/stop', methods=['POST'])
        def stop_program():
            self.is_running = False
            return {'success': True}

        print(f"üöÄ –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://{host}:{port}")
        app.run(host=host, port=port, debug=False, use_reloader=False)


# ==================== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –°–ò–°–¢–ï–ú–´ ====================
class EnhancedStockAnalysisSystem:
    def __init__(self):
        self.news_collector = NewsCollector()
        self.stock_collector = StockDataCollector()
        self.news_analyzer = NewsAnalyzer()
        self.enhanced_ai_model = EnhancedStockAIModel()
        self.portfolio = VirtualPortfolio()
        self.portfolio_rebalancer = PortfolioRebalancer(
            self.portfolio,
            threshold=0.05,
            strategy='calendar_absolute'
        )
        self.web_interface = WebInterface()

        self.news_backup_file = 'news_backup.csv'
        self.prices_backup_file = 'prices_backup.csv'
        self.recommendations_file = 'RECOM.csv'

    def run_enhanced_analysis_cycle(self):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞"""
        print("\n" + "=" * 60)
        print(f"üîç –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        try:
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
            model_status = self.enhanced_ai_model.get_model_status()
            print(f"ü§ñ –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏: {model_status}")

            # 1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
            print("üì∞ –®–∞–≥ 1: –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π...")
            news_df = self.news_collector.fetch_all_news()

            print("üìä –®–∞–≥ 2: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ü–∏—è—Ö...")
            all_tickers = [ticker for sector_tickers in RUSSIAN_SECTORS.values() for ticker in sector_tickers]
            prices_df = self.stock_collector.get_stock_prices(all_tickers)

            # 2. –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
            print("üîç –®–∞–≥ 3: –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π...")
            news_recommendations = self.news_analyzer.predict_sector_sentiment(news_df)

            # 3. –û–±—É—á–µ–Ω–∏–µ AI –º–æ–¥–µ–ª–µ–π —Å –¥–æ–æ–±—É—á–µ–Ω–∏–µ–º
            print("üéØ –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ AI –º–æ–¥–µ–ª–µ–π...")
            news_sentiment_by_date = {datetime.now().date(): news_recommendations}

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ–±—É—á–µ–Ω–∏—è: –¥–æ–æ–±—É—á–µ–Ω–∏–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞
            incremental_learning = self.enhanced_ai_model.is_trained
            training_successful = self.enhanced_ai_model.train_models(
                prices_df,
                news_sentiment_by_date,
                incremental=incremental_learning
            )

            if not training_successful:
                print("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
            else:
                training_type = "–¥–æ–æ–±—É—á–µ–Ω–∏–µ" if incremental_learning else "–ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"
                print(f"‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—à–ª–∏ {training_type}")

            # 4. AI –∞–Ω–∞–ª–∏–∑
            print("üß† –®–∞–≥ 5: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑...")
            current_prices = prices_df.iloc[-1].to_dict() if not prices_df.empty else {}
            advanced_features = self.enhanced_ai_model.create_advanced_features(prices_df, news_recommendations)

            ai_predictions = {}
            for ticker, features in advanced_features.items():
                if features:
                    prediction, confidence = self.enhanced_ai_model.predict_with_confidence(features)
                    ai_predictions[ticker] = {
                        'predicted_return': prediction,
                        'confidence': confidence,
                        'sector': self.enhanced_ai_model.get_sector_for_ticker(ticker)
                    }

            # 5. –†–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞
            print("‚öñÔ∏è –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è...")
            rebalancing_trades = self.portfolio_rebalancer.execute_rebalancing(current_prices, news_recommendations)

            # 6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            enhanced_recommendations = self._enhance_recommendations_with_ai(news_recommendations, ai_predictions)

            # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            portfolio_value = self.portfolio.get_portfolio_value(current_prices)
            self.save_backup_data(news_df, prices_df, enhanced_recommendations)
            self.web_interface.update_data(enhanced_recommendations, news_df, portfolio_value)

            # 8. –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._print_enhanced_results(enhanced_recommendations, ai_predictions, rebalancing_trades, portfolio_value)

            return True

        except Exception as e:
            print(f"üí• –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            traceback.print_exc()
            return False

    def _enhance_recommendations_with_ai(self, news_recommendations, ai_predictions):
        """–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å –ø–æ–º–æ—â—å—é AI –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"""
        enhanced_recommendations = news_recommendations.copy()

        sector_predictions = {}
        for ticker_data in ai_predictions.values():
            sector = ticker_data['sector']
            if sector not in sector_predictions:
                sector_predictions[sector] = []

            weighted_prediction = ticker_data['predicted_return'] * ticker_data['confidence']
            sector_predictions[sector].append(weighted_prediction)

        for sector, predictions in sector_predictions.items():
            if predictions:
                avg_prediction = np.mean(predictions)
                ai_adjustment = int(round(avg_prediction * 200))
                ai_adjustment = max(-5, min(5, ai_adjustment))

                if sector in enhanced_recommendations:
                    enhanced_recommendations[sector] = int(
                        0.3 * enhanced_recommendations[sector] + 0.7 * ai_adjustment
                    )
                else:
                    enhanced_recommendations[sector] = ai_adjustment

        return enhanced_recommendations

    def _print_enhanced_results(self, recommendations, ai_predictions, trades, portfolio_value):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        print("\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê:")
        print("-" * 60)

        print("üéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –°–ï–ö–¢–û–†–ê–ú:")
        for sector, rec in sorted(recommendations.items(), key=lambda x: x[1], reverse=True):
            emoji = "üü¢" if rec > 0 else "üî¥" if rec < 0 else "‚ö™"
            print(f"{emoji} {sector:30} {rec:+2d}/5")

        if trades:
            print(f"\n‚öñÔ∏è –í–´–ü–û–õ–ù–ï–ù–ù–´–ï –°–î–ï–õ–ö–ò: {len(trades)}")

        formatted_value = f"‚ÇΩ{portfolio_value:,.2f}"
        print(f"\nüíº –¢–ï–ö–£–©–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨ –ü–û–†–¢–§–ï–õ–Ø: {formatted_value}")

        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        model_info = self.enhanced_ai_model.get_training_info()
        print(f"ü§ñ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò: {model_info['total_trainings']} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫, "
              f"{model_info['samples']} samples")

        print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")

    def save_backup_data(self, news_df, prices_df, recommendations):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if not news_df.empty:
                news_df.to_csv(self.news_backup_file, index=False, encoding='utf-8-sig')

            if not prices_df.empty:
                prices_df.to_csv(self.prices_backup_file, index=False, encoding='utf-8-sig')

            rec_df = pd.DataFrame(list(recommendations.items()), columns=['–°–µ–∫—Ç–æ—Ä', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'])
            rec_df['–î–∞—Ç–∞'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            rec_df.to_csv(self.recommendations_file, index=False, encoding='utf-8-sig')

            print("üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")

    def run_continuous_analysis(self, interval_minutes=30):
        """–ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π —Å –ò–ò...")

        web_thread = threading.Thread(target=self.web_interface.run_server)
        web_thread.daemon = True
        web_thread.start()

        cycle_count = 0
        while self.web_interface.is_running:
            try:
                success = self.run_enhanced_analysis_cycle()
                cycle_count += 1

                if success:
                    print(f"\n‚ôªÔ∏è –¶–∏–∫–ª {cycle_count} –∑–∞–≤–µ—Ä—à–µ–Ω. –û–∂–∏–¥–∞–Ω–∏–µ...")
                    wait_seconds = interval_minutes * 60
                    for i in range(wait_seconds):
                        if not self.web_interface.is_running:
                            break
                        time.sleep(1)
                else:
                    print("üí§ –û–∂–∏–¥–∞–Ω–∏–µ 5 –º–∏–Ω—É—Ç –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    time.sleep(300)

            except KeyboardInterrupt:
                print("\n‚ö†Ô∏è –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
            except Exception as e:
                print(f"üí• –û—à–∏–±–∫–∞: {e}")
                time.sleep(300)

        print("üõë –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")


# ==================== –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´ ====================
if __name__ == "__main__":
    system = EnhancedStockAnalysisSystem()
    system.run_continuous_analysis(interval_minutes=1)