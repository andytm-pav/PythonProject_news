# ==================== –£–õ–£–ß–®–ï–ù–ù–´–ô –ö–õ–ê–°–° –ò–ò –ú–û–î–ï–õ–ò –° –ü–†–û–ì–ù–û–ó–û–ú –ü–û –°–ï–ö–¢–û–†–ê–ú ====================
import os
import tempfile
import traceback
from datetime import datetime
from urllib.request import urlretrieve
from collections import defaultdict

import joblib
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import BayesianRidge
from sklearn.preprocessing import StandardScaler

import library as l


class EnhancedStockAIModel:
    def __init__(self, model_path='enhanced_stock_ai_model.joblib'):
        self.model_path = model_path
        self.model = None
        self.probabilistic_model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.training_history = []
        self.model_metadata = {}
        self.sector_models = {}  # –û—Ç–¥–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞
        self.sector_scalers = {}  # –û—Ç–¥–µ–ª—å–Ω—ã–µ —Å–∫–µ–π–ª–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞
        self.current_sector_prices = {}  # –¢–µ–∫—É—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º
        self.predicted_sector_prices = {}  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ —Å—Ä–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º

        # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        self._initialize_model_with_fallback()

    def _initialize_model_with_fallback(self):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å —Å–∏—Å—Ç–µ–º–æ–π fallback"""
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–ò –º–æ–¥–µ–ª–µ–π...")

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
        if self._try_load_existing_model():
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞")
            return

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        if self._try_download_pretrained_model():
            print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
            return

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        print("üìù –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
        self._create_new_models()
        print("‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å")

    def _try_load_existing_model(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏"""
        try:
            if not os.path.exists(self.model_path):
                print("üìù –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False

            print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}")
            model_data = joblib.load(self.model_path)

            if isinstance(model_data, dict):
                return self._load_from_dict(model_data)
            else:
                return self._load_old_format(model_data)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def _try_download_pretrained_model(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            pretrained_url = l.PRETRAINED_MODEL_URLS.get('base_model')

            if not pretrained_url:
                print("‚ÑπÔ∏è URL –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–µ —É–∫–∞–∑–∞–Ω—ã")
                return False

            print(f"üåê –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            with tempfile.NamedTemporaryFile(delete=False, suffix='.joblib') as tmp_file:
                temp_path = tmp_file.name

            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                urlretrieve(pretrained_url, temp_path)

                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
                model_data = joblib.load(temp_path)

                if isinstance(model_data, dict):
                    success = self._load_from_dict(model_data)
                    if success:
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                        self._save_models()
                        print("üíæ –ü—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ")
                    return success

            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                if os.path.exists(temp_path):
                    os.unlink(temp_path)

            return False

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return False

    def _load_from_dict(self, model_data):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Å–ª–æ–≤–∞—Ä—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            required_keys = ['main_model', 'probabilistic_model', 'scaler']
            if not all(key in model_data for key in required_keys):
                print("‚ùå –í —Ñ–∞–π–ª–µ –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã")
                return False

            self.model = model_data['main_model']
            self.probabilistic_model = model_data['probabilistic_model']
            self.scaler = model_data['scaler']
            self.is_trained = model_data.get('is_trained', True)
            self.training_history = model_data.get('training_history', [])
            self.model_metadata = model_data.get('model_metadata', {})

            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            self.sector_models = model_data.get('sector_models', {})
            self.sector_scalers = model_data.get('sector_scalers', {})
            self.current_sector_prices = model_data.get('current_sector_prices', {})
            self.predicted_sector_prices = model_data.get('predicted_sector_prices', {})

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–æ–¥–µ–ª–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
            if self.model is None or self.probabilistic_model is None:
                print("‚ùå –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∞–≤–Ω—ã None")
                return False

            print(f"üìä –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(self.training_history)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫, "
                  f"{self.model_metadata.get('total_training_samples', 0)} samples")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ —Å–ª–æ–≤–∞—Ä—è: {e}")
            return False

    def _load_old_format(self, model_data):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –º–æ–¥–µ–ª–∏"""
        try:
            if isinstance(model_data, (list, tuple)) and len(model_data) >= 2:
                self.model = model_data[0]
                self.probabilistic_model = model_data[1]
                self.is_trained = True
                return True
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")
            return False

    def _create_new_models(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        try:
            # RandomForest —Å –≤–∫–ª—é—á–µ–Ω–Ω—ã–º warm_start –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                warm_start=True  # –í–∞–∂–Ω–æ –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è!
            )

            # BayesianRidge –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            self.probabilistic_model = BayesianRidge(
                n_iter=200,
                tol=1e-3
            )

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞
            self._initialize_sector_models()

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º scaler
            self.scaler = StandardScaler()

            self.is_trained = False
            self.model_metadata = {
                'creation_date': datetime.now().isoformat(),
                'total_training_samples': 0,
                'training_sessions': 0,
                'last_training': None,
                'model_type': 'EnhancedStockAIModel_v6',
                'supports_incremental_learning': True,
                'supports_sector_analysis': True
            }

            return True

        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–µ–π—à–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            self.model = RandomForestRegressor(n_estimators=10, random_state=42)
            self.probabilistic_model = BayesianRidge()
            self._initialize_sector_models()
            self.is_trained = False
            return False

    def _initialize_sector_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞"""
        try:
            for sector in l.RUSSIAN_SECTORS.keys():
                # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞
                self.sector_models[sector] = RandomForestRegressor(
                    n_estimators=50,
                    max_depth=8,
                    random_state=42,
                    warm_start=True
                )
                self.sector_scalers[sector] = StandardScaler()

            print(f"‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(self.sector_models)} –º–æ–¥–µ–ª–µ–π –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º: {e}")

    def train_models(self, prices_df, news_sentiment_by_date, incremental=False):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–æ–æ–±—É—á–µ–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ–º –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        try:
            print("üîÑ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π
            if self.model is None or self.probabilistic_model is None:
                print("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ...")
                self._create_new_models()

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
            X, y = self.prepare_training_data(prices_df, news_sentiment_by_date)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
            if not self._validate_training_data(X, y):
                print("‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return False

            print(f"üéØ –û–±—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ {len(X)} –ø—Ä–∏–º–µ—Ä–∞—Ö...")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —É—á–µ—Ç–æ–º –¥–æ–æ–±—É—á–µ–Ω–∏—è
            try:
                if self.is_trained and incremental and hasattr(self.scaler, 'n_features_in_'):
                    # –î–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è - partial_fit –∏–ª–∏ transform
                    if hasattr(self.scaler, 'partial_fit'):
                        self.scaler.partial_fit(X)
                    X_processed = self.scaler.transform(X)
                else:
                    # –ü–µ—Ä–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –ø–æ–ª–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
                    X_processed = self.scaler.fit_transform(X)
            except Exception as scale_error:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {scale_error}, –ø—Ä–∏–º–µ–Ω—è–µ–º fit_transform")
                X_processed = self.scaler.fit_transform(X)

            # –û–ë–£–ß–ï–ù–ò–ï –û–°–ù–û–í–ù–û–ô –ú–û–î–ï–õ–ò
            if self.is_trained and incremental:
                print("üìö –î–æ–æ–±—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏...")
                if hasattr(self.model, 'warm_start') and self.model.warm_start:
                    current_estimators = self.model.n_estimators
                    self.model.n_estimators = current_estimators + 50
                    self.model.fit(X_processed, y)
                else:
                    self.model.fit(X_processed, y)

                self.probabilistic_model.fit(X_processed, y)
            else:
                # –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
                print("üéì –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
                self.model.fit(X_processed, y)
                self.probabilistic_model.fit(X_processed, y)

            # –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ü–û –°–ï–ö–¢–û–†–ê–ú
            print("üè¢ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º...")
            self._train_sector_models(prices_df, news_sentiment_by_date)

            # –†–ê–°–ß–ï–¢ –¢–ï–ö–£–©–ò–• –°–†–ï–î–ù–ò–• –¶–ï–ù –ü–û –°–ï–ö–¢–û–†–ê–ú
            self._calculate_current_sector_prices(prices_df)

            # –ü–†–û–ì–ù–û–ó –°–†–ï–î–ù–ò–• –¶–ï–ù –ü–û –°–ï–ö–¢–û–†–ê–ú
            self._predict_sector_prices(prices_df, news_sentiment_by_date)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self.is_trained = True
            training_type = "incremental" if (self.is_trained and incremental) else "full"
            self._update_training_metadata(len(X), training_type)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏
            self._save_models()

            print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            traceback.print_exc()
            return False

    def _train_sector_models(self, prices_df, news_sentiment_by_date):
        """–û–±—É—á–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞"""
        try:
            for sector, tickers in l.RUSSIAN_SECTORS.items():
                # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–∏–∫–µ—Ä–æ–≤ —ç—Ç–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞
                sector_tickers = [t for t in tickers if t in prices_df.columns]

                if len(sector_tickers) < 2:  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 —Ç–∏–∫–µ—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    continue

                sector_prices = prices_df[sector_tickers]

                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–µ–∫—Ç–æ—Ä–∞
                X_sector, y_sector = self.prepare_sector_training_data(
                    sector_prices, news_sentiment_by_date, sector
                )

                if len(X_sector) > 0 and len(y_sector) > 0:
                    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å–µ–∫—Ç–æ—Ä–∞
                    X_processed = self.sector_scalers[sector].fit_transform(X_sector)
                    self.sector_models[sector].fit(X_processed, y_sector)
                    print(f"  ‚úÖ –°–µ–∫—Ç–æ—Ä '{sector}': –æ–±—É—á–µ–Ω–æ –Ω–∞ {len(X_sector)} –ø—Ä–∏–º–µ—Ä–∞—Ö")

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º: {e}")

    def _calculate_current_sector_prices(self, prices_df):
        """–†–∞—Å—á–µ—Ç —Ç–µ–∫—É—â–∏—Ö —Å—Ä–µ–¥–Ω–∏—Ö —Ü–µ–Ω –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        try:
            self.current_sector_prices = {}

            for sector, tickers in l.RUSSIAN_SECTORS.items():
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∏–∫–µ—Ä—ã
                valid_tickers = [t for t in tickers if t in prices_df.columns]

                if valid_tickers:
                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ü–µ–Ω—ã
                    sector_prices = prices_df[valid_tickers].iloc[-1].dropna()

                    if len(sector_prices) > 0:
                        avg_price = sector_prices.mean()
                        self.current_sector_prices[sector] = {
                            'average_price': float(avg_price),
                            'ticker_count': len(sector_prices),
                            'min_price': float(sector_prices.min()),
                            'max_price': float(sector_prices.max()),
                            'timestamp': datetime.now().isoformat()
                        }
                    else:
                        self.current_sector_prices[sector] = {
                            'average_price': 0.0,
                            'ticker_count': 0,
                            'min_price': 0.0,
                            'max_price': 0.0,
                            'timestamp': datetime.now().isoformat()
                        }

            print(f"üìä –†–∞—Å—Å—á–∏—Ç–∞–Ω—ã —Ç–µ–∫—É—â–∏–µ —Ü–µ–Ω—ã –¥–ª—è {len(self.current_sector_prices)} —Å–µ–∫—Ç–æ—Ä–æ–≤")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Ç–µ–∫—É—â–∏—Ö —Ü–µ–Ω –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º: {e}")

    def _predict_sector_prices(self, prices_df, news_sentiment_by_date):
        """–ü—Ä–æ–≥–Ω–æ–∑ —Å—Ä–µ–¥–Ω–∏—Ö —Ü–µ–Ω –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –∏—Ç–µ—Ä–∞—Ü–∏—é"""
        try:
            self.predicted_sector_prices = {}

            for sector, tickers in l.RUSSIAN_SECTORS.items():
                if sector not in self.sector_models:
                    continue

                # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ —Å–µ–∫—Ç–æ—Ä—É
                sector_features = self._create_sector_features(
                    sector, prices_df, news_sentiment_by_date
                )

                if sector_features and len(sector_features) > 0:
                    # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã
                    features_array = np.array(list(sector_features.values())).reshape(1, -1)
                    features_processed = self.sector_scalers[sector].transform(features_array)

                    predicted_change = self.sector_models[sector].predict(features_processed)[0]

                    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—É—é —Ü–µ–Ω—É
                    current_avg = self.current_sector_prices.get(sector, {}).get('average_price', 0)
                    predicted_price = current_avg * (1 + predicted_change)

                    self.predicted_sector_prices[sector] = {
                        'predicted_price': float(predicted_price),
                        'predicted_change': float(predicted_change),
                        'current_price': float(current_avg),
                        'confidence': 0.8,  # –ú–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–æ–¥–µ–ª–∏
                        'timestamp': datetime.now().isoformat()
                    }

            print(f"üîÆ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è {len(self.predicted_sector_prices)} —Å–µ–∫—Ç–æ—Ä–æ–≤")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º: {e}")

    def _create_sector_features(self, sector, prices_df, news_sentiment_by_date):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø–æ —Å–µ–∫—Ç–æ—Ä—É"""
        try:
            features = {}
            tickers = l.RUSSIAN_SECTORS[sector]
            valid_tickers = [t for t in tickers if t in prices_df.columns]

            if not valid_tickers:
                return None

            sector_prices = prices_df[valid_tickers]

            # –ë–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–µ–∫—Ç–æ—Ä—É
            current_prices = sector_prices.iloc[-1].dropna()
            if len(current_prices) == 0:
                return None

            returns = sector_prices.pct_change().dropna()

            features['sector_volatility'] = returns.std().mean() if not returns.empty else 0.02
            features['sector_momentum'] = (sector_prices.iloc[-1] / sector_prices.iloc[-5] - 1).mean() if len(
                sector_prices) >= 5 else 0
            features['sector_volume'] = len(valid_tickers) / len(tickers)  # –î–æ–ª—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤

            # –°–µ–Ω—Ç–∏–º–µ–Ω—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ —Å–µ–∫—Ç–æ—Ä—É
            current_sentiment = {}
            if news_sentiment_by_date:
                latest_date = max(news_sentiment_by_date.keys())
                current_sentiment = news_sentiment_by_date[latest_date]

            features['sector_sentiment'] = current_sentiment.get(sector, 0)

            # –û–±—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã
            features['market_trend'] = prices_df.mean(axis=1).pct_change().iloc[-1] if len(prices_df) > 1 else 0

            return features

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–µ–∫—Ç–æ—Ä–∞ {sector}: {e}")
            return None

    def prepare_sector_training_data(self, sector_prices, news_sentiment_by_date, sector):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π —Å–µ–∫—Ç–æ—Ä–æ–≤"""
        X, y = [], []

        if sector_prices.empty:
            return np.array([]), np.array([])

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤
            for i in range(10, len(sector_prices)):
                # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ –æ–∫–Ω–æ –¥–ª—è —Ñ–∏—á–µ–π
                historical_window = sector_prices.iloc[i - 10:i]

                if historical_window.empty:
                    continue

                # –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏ –∏–∑ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –æ–∫–Ω–∞
                features = self._create_historical_sector_features(
                    historical_window, news_sentiment_by_date, sector, i
                )

                if features:
                    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –≤ —Å–ª–µ–¥—É—é—â–µ–º –ø–µ—Ä–∏–æ–¥–µ
                    if i < len(sector_prices) - 1:
                        current_avg = historical_window.iloc[-1].mean()
                        next_avg = sector_prices.iloc[i + 1].mean()
                        price_change = (next_avg - current_avg) / current_avg if current_avg != 0 else 0

                        X.append(list(features.values()))
                        y.append(price_change)

            return np.array(X), np.array(y)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ–∫—Ç–æ—Ä–∞ {sector}: {e}")
            return np.array([]), np.array([])

    def _create_historical_sector_features(self, historical_prices, news_sentiment_by_date, sector, index):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–µ–∫—Ç–æ—Ä–∞"""
        try:
            features = {}

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ü–µ–Ω
            current_prices = historical_prices.iloc[-1].dropna()
            if len(current_prices) == 0:
                return None

            returns = historical_prices.pct_change().dropna()

            features['hist_volatility'] = returns.std().mean() if not returns.empty else 0.02
            features['price_momentum'] = (historical_prices.iloc[-1] / historical_prices.iloc[-5] - 1).mean() if len(
                historical_prices) >= 5 else 0
            features['price_trend'] = (historical_prices.iloc[-1] / historical_prices.iloc[0] - 1).mean()

            # –°–µ–Ω—Ç–∏–º–µ–Ω—Ç –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –¥–∞—Ç—É
            sentiment_date = historical_prices.index[-1].date() if hasattr(historical_prices.index[-1], 'date') else \
            historical_prices.index[-1]
            sector_sentiment = 0

            for date, sentiment_dict in news_sentiment_by_date.items():
                if date == sentiment_date:
                    sector_sentiment = sentiment_dict.get(sector, 0)
                    break

            features['hist_sentiment'] = sector_sentiment

            return features

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None

    def get_sector_analysis(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º"""
        return {
            'current_sector_prices': self.current_sector_prices,
            'predicted_sector_prices': self.predicted_sector_prices,
            'analysis_timestamp': datetime.now().isoformat(),
            'sectors_analyzed': list(self.current_sector_prices.keys())
        }

    def _update_training_metadata(self, new_samples_count, training_type):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        current_total = self.model_metadata.get('total_training_samples', 0)
        self.model_metadata['total_training_samples'] = current_total + new_samples_count
        self.model_metadata['training_sessions'] = self.model_metadata.get('training_sessions', 0) + 1
        self.model_metadata['last_training'] = datetime.now().isoformat()
        self.model_metadata['last_training_type'] = training_type
        self.model_metadata['sector_models_count'] = len(self.sector_models)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫
        self.training_history.append({
            'timestamp': datetime.now().isoformat(),
            'samples': new_samples_count,
            'total_samples': self.model_metadata['total_training_samples'],
            'type': training_type,
            'sectors_analyzed': len(self.current_sector_prices)
        })

    @staticmethod
    def _validate_training_data(X, y):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if X is None or y is None:
            print("‚ùå –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Ä–∞–≤–Ω—ã None")
            return False

        if len(X) == 0 or len(y) == 0:
            print("‚ùå –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False

        if len(X) != len(y):
            print("‚ùå –ù–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ X –∏ y")
            return False

        return True

    def _save_models(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
        try:
            if self.model is None or self.probabilistic_model is None:
                print("‚ö†Ô∏è –ù–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å: –º–æ–¥–µ–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
                return False

            models_to_save = {
                'main_model': self.model,
                'probabilistic_model': self.probabilistic_model,
                'scaler': self.scaler,
                'is_trained': self.is_trained,
                'training_history': self.training_history,
                'model_metadata': self.model_metadata,
                'sector_models': self.sector_models,
                'sector_scalers': self.sector_scalers,
                'current_sector_prices': self.current_sector_prices,
                'predicted_sector_prices': self.predicted_sector_prices
            }

            joblib.dump(models_to_save, self.model_path)
            print(f"üíæ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.model_path}")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            return False

    def create_advanced_features(self, prices_df, news_sentiment):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        features = {}

        if prices_df.empty:
            print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return features

        for ticker in prices_df.columns:
            try:
                if ticker not in prices_df:
                    continue

                price_series = prices_df[ticker].dropna()
                if len(price_series) < 30:
                    continue

                # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                returns = price_series.pct_change().dropna()
                if len(returns) < 15:
                    continue

                # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                volatility = returns.std()
                current_price = price_series.iloc[-1]
                ma_short = price_series.rolling(window=5).mean().iloc[-1]
                ma_long = price_series.rolling(window=20).mean().iloc[-1]

                features[ticker] = {
                    'volatility': float(volatility) if not pd.isna(volatility) else 0.02,
                    'price_ratio': float(current_price / ma_long) if ma_long != 0 else 1.0,
                    'ma_ratio': float(ma_short / ma_long) if ma_long != 0 else 1.0,
                    'sector_sentiment': float(news_sentiment.get(self.get_sector_for_ticker(ticker), 0))
                }

            except Exception as e:
                print(e)  # TODO: define
                continue

        return features

    @staticmethod
    def get_sector_for_ticker(ticker):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Ç–∏–∫–µ—Ä–∞"""
        for sector, tickers in l.RUSSIAN_SECTORS.items():
            if ticker in tickers:
                return sector
        return '–û–±—â–∏–µ'

    def prepare_training_data(self, prices_df, news_sentiment_by_date, forecast_days=5):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        X, y = [], []

        if prices_df.empty:
            return np.array([]), np.array([])

        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        current_sentiment = {}
        if news_sentiment_by_date:
            latest_date = max(news_sentiment_by_date.keys())
            current_sentiment = news_sentiment_by_date[latest_date]

        features_dict = self.create_advanced_features(prices_df, current_sentiment)

        for ticker, features in features_dict.items():
            if features and len(features) > 0:
                feature_vector = list(features.values())
                # –ü—Ä–æ—Å—Ç–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                target = np.random.uniform(-0.1, 0.1)  # –ó–∞–º–µ–Ω–∏—Ç–µ —Ä–µ–∞–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
                X.append(feature_vector)
                y.append(target)

        if len(X) > 0:
            return np.array(X), np.array(y)
        else:
            return np.array([]), np.array([])

    def predict_with_confidence(self, current_features):
        """–ü—Ä–æ–≥–Ω–æ–∑ —Å –æ—Ü–µ–Ω–∫–æ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏"""
        if not self.is_trained or self.model is None:
            return 0.0, 0.0

        try:
            if isinstance(current_features, dict):
                feature_vector = list(current_features.values())
            else:
                feature_vector = current_features

            if len(feature_vector) == 0:
                return 0.0, 0.0

            features_array = np.array(feature_vector).reshape(1, -1)
            features_array = self.scaler.transform(features_array)

            main_pred = self.model.predict(features_array)[0]
            probabilistic_pred, probabilistic_std = self.probabilistic_model.predict(features_array, return_std=True)

            combined_pred = 0.7 * main_pred + 0.3 * probabilistic_pred
            confidence = max(0.0, min(1.0, 1.0 - probabilistic_std[0]))

            return float(combined_pred), float(confidence)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return 0.0, 0.0

    def get_training_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ –º–æ–¥–µ–ª–∏"""
        if not self.training_history:
            return "–ú–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –æ–±—É—á–∞–ª–∞—Å—å"

        latest = self.training_history[-1]
        return {
            'last_training': latest['timestamp'],
            'samples': latest['total_samples'],
            'total_trainings': len(self.training_history),
            'model_metadata': self.model_metadata,
            'sector_analysis_available': len(self.current_sector_prices) > 0
        }

    def get_model_status(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏"""
        return {
            'is_trained': self.is_trained,
            'model_initialized': self.model is not None,
            'training_sessions': len(self.training_history),
            'total_samples': self.model_metadata.get('total_training_samples', 0),
            'supports_incremental': self.model_metadata.get('supports_incremental_learning', False),
            'sector_models_count': len(self.sector_models),
            'current_sector_data': len(self.current_sector_prices),
            'predicted_sector_data': len(self.predicted_sector_prices)
        }

  #  print(f"ü§ñ–Ω–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑: {is_trained}")