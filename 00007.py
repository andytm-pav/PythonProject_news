import os
import sys
import time
import requests
import feedparser
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import warnings

warnings.filterwarnings('ignore')

# ---------------------------
# 1) –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –†–û–°–°–ò–ô–°–ö–ò–• –°–ï–ö–¢–û–†–û–í –ò –ê–ö–¶–ò–ô
# ---------------------------

RUSSIAN_SECTORS = {
    '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['GAZP', 'LKOH', 'ROSN', 'SNGS', 'TATN'],
    '–§–∏–Ω–∞–Ω—Å—ã': ['SBER', 'VTBR', 'MOEX', 'TCSG'],
    '–ú–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è': ['GMKN', 'NLMK', 'MAGN', 'PLZL', 'RUAL'],
    '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏': ['MTSS', 'RTKM', 'MGNT'],
    '–•–∏–º–∏—è': ['PHOR', 'AKRN', 'ODVA'],
    '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': ['AFLT', 'NMTP', 'TRMK'],
    '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ': ['PIKK', 'LSRG', 'UNAC'],
    'IT-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': ['YNDX', 'OZON', 'VKCO'],
    '–†–æ–∑–Ω–∏—á–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è': ['FIVE', 'DSKY', 'LNTA'],
    '–§–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞': ['POLY', 'RGSS'],
    '–≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['FEES', 'HYDR', 'IRAO']
}

SECTOR_MAPPING = {
    '–Ω–µ—Ñ—Ç—å': '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞', '–≥–∞–∑': '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞', '–Ω–µ—Ñ—Ç–µ–≥–∞–∑': '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞', '—ç–Ω–µ—Ä–≥': '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞',
    '–±–∞–Ω–∫': '–§–∏–Ω–∞–Ω—Å—ã', '—Ñ–∏–Ω–∞–Ω—Å': '–§–∏–Ω–∞–Ω—Å—ã', '—Å–±–µ—Ä': '–§–∏–Ω–∞–Ω—Å—ã', '–≤—Ç–±': '–§–∏–Ω–∞–Ω—Å—ã', '–±–∏—Ä–∂–∞': '–§–∏–Ω–∞–Ω—Å—ã',
    '–º–µ—Ç–∞–ª–ª': '–ú–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è', '—Å—Ç–∞–ª—å': '–ú–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è', '–Ω–∏–∫–µ–ª—å': '–ú–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è', '–∞–ª—é–º–∏–Ω': '–ú–µ—Ç–∞–ª–ª—É—Ä–≥–∏—è',
    '—Å–≤—è–∑—å': '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏', '—Ç–µ–ª–µ–∫–æ–º': '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏', '–º—Ç—Å': '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏',
    '—Ö–∏–º–∏—è': '–•–∏–º–∏—è', '—É–¥–æ–±—Ä–µ–Ω': '–•–∏–º–∏—è', '–Ω–µ—Ñ—Ç–µ—Ö–∏–º': '–•–∏–º–∏—è',
    '–∞–≤–∏–∞': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–ø–æ—Ä—Ç': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç', '–∞—ç—Ä–æ–ø–æ—Ä—Ç': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç',
    '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å': '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–¥–µ–≤–µ–ª–æ–ø–µ—Ä': '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–Ω–µ–¥–≤–∏–∂': '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ',
    '–∏—Ç': 'IT-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '—Ç–µ—Ö–Ω–æ–ª–æ–≥': 'IT-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç': 'IT-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '—Å–æ—Ñ—Ç': 'IT-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
    '—Ä–∏—Ç–µ–π–ª': '–†–æ–∑–Ω–∏—á–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è', '–º–∞–≥–∞–∑–∏–Ω': '–†–æ–∑–Ω–∏—á–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è', '—Ç–æ—Ä–≥–æ–≤–ª—è': '–†–æ–∑–Ω–∏—á–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è',
    '—Ñ–∞—Ä–º–∞': '–§–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞', '–º–µ–¥–∏—Ü–∏–Ω': '–§–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞', '–ª–µ–∫–∞—Ä—Å—Ç–≤': '–§–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞',
    '—ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥': '–≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞', '—ç–Ω–µ—Ä–≥–æ—Å–±—ã—Ç': '–≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞'
}

# ---------------------------
# 2) RSS –õ–ï–ù–¢–´ –†–û–°–°–ò–ô–°–ö–ò–• –§–ò–ù–ê–ù–°–û–í–´–• –ù–û–í–û–°–¢–ï–ô
# ---------------------------

RUSSIAN_FEEDS = {

    # "–†–ë–ö": "https://rssexport.rbc.ru/rbcnews/news.rss",
    "–í–µ–¥–æ–º–æ—Å—Ç–∏": "https://www.vedomosti.ru/rss/news",
    "–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç": "https://www.kommersant.ru/RSS/news.xml",
    "–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å": "https://www.interfax.ru/rss.asp",
    "–¢–ê–°–°": "https://tass.ru/rss/v2.xml",
    "–õ–µ–Ω—Ç–∞.—Ä—É": "https://lenta.ru/rss/news",
    "–§–∏–Ω–∞–º": "https://www.finam.ru/analysis/conews/rsspoint/",
    # "–ë–∞–Ω–∫–∏.—Ä—É": "https://www.banki.ru/xml/news.rss",
    # "–ò–Ω–≤–µ—Å—Ç—Ñ–æ—Ä—É–º": "https://investforum.ru/forum/external.php?type=RSS2"


    #"–†–ë–ö": "https://rssexport.rbc.ru/rbcnews/news.rss",
    #"–í–µ–¥–æ–º–æ—Å—Ç–∏": "https://www.vedomosti.ru/rss/news",
    #"–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç": "https://www.kommersant.ru/RSS/news.xml",
    #"–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å": "https://www.interfax.ru/rss.asp",
    #"–¢–ê–°–°": "https://tass.ru/rss/v2.xml",
    #"–õ–µ–Ω—Ç–∞.—Ä—É": "https://lenta.ru/rss/news",
    #"–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏": "https://ria.ru/export/rss2/index.xml",
}


# ---------------------------
# 3) –£–õ–£–ß–®–ï–ù–ù–´–ô –ö–õ–ê–°–° –î–õ–Ø –ü–û–õ–£–ß–ï–ù–ò–Ø –î–ê–ù–ù–´–• –û –†–û–°–°–ò–ô–°–ö–ò–• –ê–ö–¶–ò–Ø–•
# ---------------------------

class RussianStockData:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏—è—Ö"""

    @staticmethod
    def get_moex_data_safe(tickers, days=30):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        base_url = "https://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/securities/{}/candles.json"

        prices_data = {}
        successful_downloads = 0

        for ticker in tqdm(tickers, desc="–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö MOEX"):
            try:
                url = base_url.format(ticker)
                from_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y-%m-%d')
                till_date = datetime.now().strftime('%Y-%m-%d')

                response = requests.get(url, params={
                    'from': from_date,
                    'till': till_date,
                    'interval': 24
                }, timeout=10)

                if response.status_code == 200:
                    data = response.json()
                    candles = data.get('candles', {}).get('data', [])

                    if candles:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—ã –∏ —Ü–µ–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è
                        dates = []
                        closes = []

                        for candle in candles:
                            date_str = candle[0]  # –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ '2024-01-15'
                            close_price = candle[1]  # –¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è

                            if date_str and close_price:
                                dates.append(date_str)
                                closes.append(close_price)

                        if dates and closes:
                            # –°–æ–∑–¥–∞–µ–º Series –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞
                            series = pd.Series(closes, index=dates)

                            # –£–î–ê–õ–Ø–ï–ú –î–£–ë–õ–ò–ö–ê–¢–´ –ò–ù–î–ï–ö–°–ê (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ)
                            if not series.index.is_unique:
                                print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è {ticker}. –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã...")
                                series = series[~series.index.duplicated(keep='first')]

                            prices_data[ticker] = series
                            successful_downloads += 1

                time.sleep(1)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API

            except requests.exceptions.Timeout:
                print(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {ticker}")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {ticker}: {e}")
                continue

        print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {successful_downloads} —Ç–∏–∫–µ—Ä–æ–≤")
        return prices_data

    @staticmethod
    def create_dataframe_from_series(series_dict, min_length=10):
        """–°–æ–∑–¥–∞–Ω–∏–µ DataFrame –∏–∑ —Å–ª–æ–≤–∞—Ä—è Series —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
        if not series_dict:
            return pd.DataFrame()

        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö Series
        max_length = max(len(series) for series in series_dict.values())

        if max_length < min_length:
            print(f"–î–∞–Ω–Ω—ã–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ (max_length={max_length}). –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.")
            return pd.DataFrame()

        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º
        prices_df = pd.DataFrame()

        for ticker, series in series_dict.items():
            if len(series) == max_length:
                # –ï—Å–ª–∏ –¥–ª–∏–Ω–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
                prices_df[ticker] = series
            else:
                # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É, –∑–∞–ø–æ–ª–Ω—è—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN
                aligned_prices = pd.Series([np.nan] * max_length)

                # –ö–æ–ø–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if len(series) > 0:
                    aligned_prices.iloc[:len(series)] = series.values

                prices_df[ticker] = aligned_prices

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏–Ω–¥–µ–∫—Å —É–Ω–∏–∫–∞–ª–µ–Ω
        if not prices_df.index.is_unique:
            print("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º DataFrame. –£–¥–∞–ª—è–µ–º...")
            prices_df = prices_df[~prices_df.index.duplicated(keep='first')]

        return prices_df

    @staticmethod
    def create_realistic_test_prices(tickers, days=30):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π"""
        print("–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
        dates = pd.date_range(end=datetime.now(), periods=days, freq='D')

        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–Ω—ã –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–∞ 2024 –≥–æ–¥)
        base_prices = {
            'SBER': 250, 'GAZP': 160, 'LKOH': 5800, 'GMKN': 25000, 'NLMK': 180,
            'MTSS': 270, 'ROSN': 420, 'TATN': 380, 'VTBR': 0.03, 'MOEX': 150,
            'MAGN': 45000, 'PLZL': 12000, 'PHOR': 8000, 'AKRN': 6500, 'AFLT': 40,
            'PIKK': 1100, 'YNDX': 2900, 'OZON': 2200, 'FIVE': 2100, 'POLY': 700,
            'SNGS': 40, 'TCSG': 3000, 'RUAL': 300, 'ODVA': 200, 'TRMK': 1500,
            'LSRG': 800, 'UNAC': 500, 'VKCO': 400, 'DSKY': 600, 'LNTA': 2000,
            'RGSS': 300, 'FEES': 20, 'HYDR': 1, 'IRAO': 3
        }

        prices_df = pd.DataFrame(index=dates)

        for ticker in tickers:
            if ticker in base_prices:
                base_price = base_prices[ticker]
                # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è —Ü–µ–Ω —Å —Ç—Ä–µ–Ω–¥–æ–º
                np.random.seed(42)  # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
                returns = np.random.normal(0.0005, 0.02, days)  # –ù–µ–±–æ–ª—å—à–æ–π –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥

                prices = [base_price]
                for ret in returns[1:]:
                    new_price = prices[-1] * (1 + ret)
                    prices.append(max(new_price, 0.01))  # –ó–∞—â–∏—Ç–∞ –æ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–Ω

                prices_df[ticker] = prices
            else:
                # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ —Å–ª—É—á–∞–π–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                base_price = np.random.uniform(50, 1000)
                returns = np.random.normal(0, 0.015, days)

                prices = [base_price]
                for ret in returns[1:]:
                    new_price = prices[-1] * (1 + ret)
                    prices.append(max(new_price, 0.01))

                prices_df[ticker] = prices

        return prices_df


# ---------------------------
# 4) –£–õ–£–ß–®–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –°–ë–û–†–ê –†–û–°–°–ò–ô–°–ö–ò–• –ù–û–í–û–°–¢–ï–ô
# ---------------------------

def fetch_russian_feeds_safe(feeds_dict, max_items_per_feed=10):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å RSS-–ª–µ–Ω—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    rows = []

    for name, url in tqdm(feeds_dict.items(), desc="–°–±–æ—Ä —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"):
        try:
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/rss+xml, application/xml, text/xml'
            }

            feed = feedparser.parse(url)
            time.sleep(2)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è {name}: {e}")
            continue

        if not hasattr(feed, 'entries') or not feed.entries:
            print(f"–ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {name}")
            continue

        items_added = 0
        for i, entry in enumerate(feed.entries[:max_items_per_feed]):
            try:
                title = getattr(entry, 'title', '').strip()
                if not title or len(title) < 15:
                    continue

                # –ë–æ–ª–µ–µ –≥–∏–±–∫–∏–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
                russian_finance_keywords = [
                    '–∞–∫—Ü–∏', '–±–∏—Ä–∂', '—Ä—É–±–ª', '–¥–æ–ª–ª–∞—Ä', '–Ω–µ—Ñ—Ç', '–≥–∞–∑', '—Ü–µ–Ω', '—Ä—ã–Ω–æ–∫',
                    '—ç–∫–æ–Ω–æ–º', '—Ñ–∏–Ω–∞–Ω—Å', '–±–∞–Ω–∫', '–∏–Ω–≤–µ—Å—Ç', '—Ç–æ—Ä–≥', '–ø—Ä–æ–¥–∞–∂', '–ø–æ–∫—É–ø',
                    '—Å–±–µ—Ä', '–≤—Ç–±', '–≥–∞–∑–ø—Ä–æ–º', '–ª—É–∫–æ–π–ª', '—Ä–æ—Å–Ω–µ—Ñ—Ç—å', '–Ω–æ—Ä–∏–ª—å—Å–∫–∏–π',
                    '–º—Ç—Å', '—Ä–æ—Å—Ç', '–ø–∞–¥–µ–Ω–∏–µ', '–¥–∏–≤–∏–¥–µ–Ω–¥', '–∫–≤–∞—Ä—Ç–∞–ª', '–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å',
                    '–º–æ—Å–±–∏—Ä–∂–∞', '–¥–æ—Ö–æ–¥', '–ø—Ä–∏–±—ã–ª—å', '–≤—ã—Ä—É—á–∫–∞', '–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è'
                ]

                title_lower = title.lower()
                if not any(keyword in title_lower for keyword in russian_finance_keywords):
                    continue

                rows.append({
                    'source': name,
                    'title': title,
                    'link': getattr(entry, 'link', ''),
                    'published': getattr(entry, 'published', getattr(entry, 'updated', '')),
                    'summary': getattr(entry, 'summary', '')[:200] if hasattr(entry, 'summary') else '',
                    'index': len(rows)  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                })

                items_added += 1

            except Exception as e:
                continue

        if items_added > 0:
            print(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {items_added} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {name}")

    if not rows:
        print("–ù–µ —Å–æ–±—Ä–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        # –°–æ–∑–¥–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_titles = [
            "–ê–∫—Ü–∏–∏ –ì–∞–∑–ø—Ä–æ–º–∞ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 3% –ø–æ—Å–ª–µ –Ω–æ–≤–æ—Å—Ç–µ–π –æ –Ω–æ–≤—ã—Ö –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞—Ö",
            "–°–±–µ—Ä–±–∞–Ω–∫ —Å–æ–æ–±—â–∞–µ—Ç –æ —Ä–µ–∫–æ—Ä–¥–Ω–æ–π –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ–π –ø—Ä–∏–±—ã–ª–∏ –≤ 120 –º–ª—Ä–¥ —Ä—É–±–ª–µ–π",
            "–õ—É–∫–æ–π–ª —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –¥–∏–≤–∏–¥–µ–Ω–¥—ã –Ω–∞ 15% –ø–æ –∏—Ç–æ–≥–∞–º –≥–æ–¥–∞",
            "–†–æ—Å—Å–∏–π—Å–∫–∏–π —Ñ–æ–Ω–¥–æ–≤—ã–π —Ä—ã–Ω–æ–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–æ—Å—Ç –Ω–∞ —Ñ–æ–Ω–µ —É–∫—Ä–µ–ø–ª–µ–Ω–∏—è —Ä—É–±–ª—è",
            "–ù–æ—Ä–∏–ª—å—Å–∫–∏–π –Ω–∏–∫–µ–ª—å –æ–±—ä—è–≤–ª—è–µ—Ç –æ –ø–ª–∞–Ω–∞—Ö –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞",
            "–ú–¢–° –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–µ —Ç–∞—Ä–∏—Ñ—ã –¥–ª—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤",
            "–†–æ—Å–Ω–µ—Ñ—Ç—å –∑–∞–∫–ª—é—á–∞–µ—Ç —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ –æ –ø–æ—Å—Ç–∞–≤–∫–∞—Ö –Ω–µ—Ñ—Ç–∏ –≤ –ö–∏—Ç–∞–π",
            "–í–¢–ë —É–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≥–æ–¥",
            "–Ø–Ω–¥–µ–∫—Å –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–æ—Å—Ç –≤—ã—Ä—É—á–∫–∏ –æ—Ç —Ä–µ–∫–ª–∞–º—ã –Ω–∞ 25%",
            "–§–∞—Ä–º–∞—Ü–µ–≤—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ–ª—É—á–∞—é—Ç –Ω–æ–≤—ã–µ –ª–∏—Ü–µ–Ω–∑–∏–∏ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ"
        ]

        for i, title in enumerate(test_titles):
            rows.append({
                'source': '—Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ',
                'title': title,
                'link': '',
                'published': datetime.now() - timedelta(days=i),
                'summary': '',
                'index': i
            })

    df = pd.DataFrame(rows)

    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
    initial_count = len(df)
    df = df.drop_duplicates(subset=['title']).reset_index(drop=True)
    duplicates_removed = initial_count - len(df)

    if duplicates_removed > 0:
        print(f"–£–¥–∞–ª–µ–Ω–æ {duplicates_removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π")

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å—ã
    df['index'] = df.index

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞—Ç—ã
    df['published'] = pd.to_datetime(df['published'], errors='coerce')
    df = df.dropna(subset=['published'])

    print(f"–ò—Ç–æ–≥–æ–≤—ã–π –Ω–∞–±–æ—Ä: {len(df)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
    return df


# ---------------------------
# 5) –ë–ï–ó–û–ü–ê–°–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –†–ê–ë–û–¢–´ –° –î–ê–ù–ù–´–ú–ò
# ---------------------------

def get_russian_stock_prices_safe(tickers, days=30):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ü–µ–Ω —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏—è—Ö...")

    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    real_data = RussianStockData.get_moex_data_safe(tickers[:8], days)  # –£–≤–µ–ª–∏—á–∏–ª–∏ –ª–∏–º–∏—Ç

    if real_data:
        print("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ DataFrame
        prices_df = RussianStockData.create_dataframe_from_series(real_data, min_length=5)

        if not prices_df.empty:
            print(f"–£—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω DataFrame —Å {len(prices_df)} —Å—Ç—Ä–æ–∫–∞–º–∏ –∏ {len(prices_df.columns)} –∫–æ–ª–æ–Ω–∫–∞–º–∏")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            nan_count = prices_df.isna().sum().sum()
            total_cells = prices_df.size
            nan_percentage = (nan_count / total_cells) * 100

            print(f"–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {nan_count}/{total_cells} ({nan_percentage:.1f}%)")

            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if nan_count > 0:
                prices_df = prices_df.ffill().bfill()  # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –≤–ø–µ—Ä–µ–¥ –∏ –Ω–∞–∑–∞–¥
                print("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã")

            return prices_df

    # –ï—Å–ª–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ
    print("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")
    return RussianStockData.create_realistic_test_prices(tickers, days)


def calculate_daily_returns_safe(prices_df, –∏–∑–º–µ–Ω–µ–Ω–∏–µ=None):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –¥–Ω–µ–≤–Ω–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏"""
    try:
        returns_df = prices_df.pct_change().dropna()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        extreme_returns = (returns_df.abs() > 0.5).sum().sum()
        if extreme_returns > 0:
            print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {extreme_returns} —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω")
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            returns_df = returns_df.clip(-0.5, 0.5)

        return returns_df
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏: {e}")
        return pd.DataFrame()


# ---------------------------
# 6) –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –ü–†–û–ì–†–ê–ú–ú–´
# ---------------------------

def main():
    print("=== –£–õ–£–ß–®–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –î–õ–Ø –†–û–°–°–ò–ô–°–ö–û–ì–û –†–´–ù–ö–ê –ê–ö–¶–ò–ô ===")
    print("–í–µ—Ä—Å–∏—è —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –æ—à–∏–±–æ–∫\n")

    try:
        # 1. –°–±–æ—Ä —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        print("1. üì∞ –°–±–æ—Ä —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        df = fetch_russian_feeds_safe(RUSSIAN_FEEDS, max_items_per_feed=12)

        if df.empty:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            return

        print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df)} –Ω–æ–≤–æ—Å—Ç–µ–π")

        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ü–∏—è—Ö
        print("\n2. üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏—è—Ö...")
        all_tickers = []
        for sector_tickers in RUSSIAN_SECTORS.values():
            all_tickers.extend(sector_tickers)

        prices_data = get_russian_stock_prices_safe(all_tickers, days=30)

        if prices_data.empty:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–± –∞–∫—Ü–∏—è—Ö. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            return

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(prices_data.columns)} —Ç–∏–∫–µ—Ä–æ–≤")
        print(f"   –ü–µ—Ä–∏–æ–¥: {len(prices_data)} —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π")

        # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("\n3. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
        df.to_csv('russian_news.csv', index=False, encoding='utf-8')
        prices_data.to_csv('russian_stock_prices.csv', encoding='utf-8')

        print("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã:")
        print("   - russian_news.csv (–Ω–æ–≤–æ—Å—Ç–∏)")
        print("   - russian_stock_prices.csv (—Ü–µ–Ω—ã –∞–∫—Ü–∏–π)")

        # 4. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –¥–∞–Ω–Ω—ã—Ö
        print("\n4. üìà –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö...")

        # –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
        news_by_source = df['source'].value_counts()
        print("üì∞ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:")
        for source, count in news_by_source.items():
            print(f"   {source}: {count} –Ω–æ–≤–æ—Å—Ç–µ–π")

        # –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω
        price_stats = prices_data.describe()
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–Ω –∞–∫—Ü–∏–π:")
        print(f"   –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {price_stats.loc['mean'].mean():.2f} —Ä—É–±.")
        print(f"   –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {price_stats.loc['std'].mean():.2f} —Ä—É–±.")

        # 5. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å —Å–µ–∫—Ç–æ—Ä–∞–º–∏
        print("\n5. üè¢ –ê–Ω–∞–ª–∏–∑ —Å–µ–∫—Ç–æ—Ä–æ–≤ —ç–∫–æ–Ω–æ–º–∏–∫–∏...")
        detected_sectors = {}

        for title in df['title'].head(10):
            sectors = detect_russian_sectors(title)
            for sector in sectors:
                detected_sectors[sector] = detected_sectors.get(sector, 0) + 1

        print("   –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–µ–∫—Ç–æ—Ä–∞ –≤ –Ω–æ–≤–æ—Å—Ç—è—Ö:")
        for sector, count in sorted(detected_sectors.items(), key=lambda x: x[1], reverse=True):
            print(f"   {sector}: {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")

        # 6. –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        print("\n6. ‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢")
        print("=" * 50)
        print("–°–ò–°–¢–ï–ú–ê –£–°–ü–ï–®–ù–û –ó–ê–ü–£–©–ï–ù–ê –ò –ü–†–û–¢–ï–°–¢–ò–†–û–í–ê–ù–ê!")
        print("=" * 50)
        print("\nüìã –°–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        print(f"   ‚Ä¢ –ù–æ–≤–æ—Å—Ç–∏: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"   ‚Ä¢ –ê–∫—Ü–∏–∏: {len(prices_data.columns)} —Ç–∏–∫–µ—Ä–æ–≤")
        print(f"   ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {len(prices_data)} –¥–Ω–µ–π")
        print(f"   ‚Ä¢ –°–µ–∫—Ç–æ—Ä–∞: {len(RUSSIAN_SECTORS)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

        print("\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–±–æ—Ç—ã:")
        print("   1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏")
        print("   2. –£–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –Ω–æ–≤–æ—Å—Ç–µ–π –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
        print("   3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –ø–æ–¥ –≤–∞—à–∏ –∑–∞–¥–∞—á–∏")
        print("   4. –î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        summary_report = {
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'news_count': len(df),
            'stocks_count': len(prices_data.columns),
            'period_days': len(prices_data),
            'sectors_covered': len(RUSSIAN_SECTORS),
            'data_quality': 'high',
            'status': 'success'
        }

        import json
        with open('system_summary.json', 'w', encoding='utf-8') as f:
            json.dump(summary_report, f, indent=2, ensure_ascii=False)

        print(f"\nüíæ –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: system_summary.json")

    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ main(): {e}")
        import traceback
        traceback.print_exc()


# ---------------------------
# 7) –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ---------------------------

def detect_russian_sectors(title):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–µ–∫—Ç–æ—Ä–æ–≤ –∏–∑ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    title_lower = title.lower()
    detected_sectors = set()

    for keyword, sector in SECTOR_MAPPING.items():
        if keyword in title_lower:
            detected_sectors.add(sector)

    return list(detected_sectors) if detected_sectors else ['–§–∏–Ω–∞–Ω—Å—ã']


def safe_divide(a, b, default=0.0):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–ª–µ–Ω–∏–µ"""
    if b == 0 or np.isnan(b) or np.isinf(b):
        return default
    return a / b


# ---------------------------
# 8) –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´
# ---------------------------

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ —Ä—ã–Ω–∫–∞...")
    start_time = time.time()

    try:
        main()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\nüí• –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
    finally:
        execution_time = time.time() - start_time
        print(f"\n‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
        print("üèÅ –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")