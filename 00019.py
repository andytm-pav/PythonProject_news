import os
import sys
import time
import requests
import feedparser
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import joblib
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import BayesianRidge
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.impute import SimpleImputer
import re
import threading
from flask import Flask, render_template_string, request, jsonify
import json
import traceback
from urllib.request import urlretrieve
import zipfile
import tempfile
from scipy.optimize import minimize
import logging
from logging.handlers import RotatingFileHandler
import hashlib
from functools import wraps
import asyncio
#import aiohttp
import concurrent.futures

from news_analyzer import NewsAnalyzer
from news_collector import NewsCollector
from stock_data_collector import StockDataCollector
from virtual_portfolio import VirtualPortfolio
from web_interface import WebInterface

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ì–ò–†–û–í–ê–ù–ò–Ø ====================
warnings.filterwarnings('ignore')


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
def setup_logging():
    logger = logging.getLogger('StockAnalysis')
    logger.setLevel(logging.INFO)

    # –§–æ—Ä–º–∞—Ç—Ç–µ—Ä
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
    )

    # File handler
    file_handler = RotatingFileHandler(
        'stock_analysis.log', maxBytes=10 * 1024 * 1024, backupCount=5
    )
    file_handler.setFormatter(formatter)

    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger


logger = setup_logging()


# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò ====================
class SecurityConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π"""

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
    MAX_DRAWDOWN = 0.15  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ 15%
    SECTOR_LIMITS = 0.25  # –ù–µ –±–æ–ª–µ–µ 25% –≤ –æ–¥–∏–Ω —Å–µ–∫—Ç–æ—Ä
    POSITION_SIZING = 0.1  # –ù–µ –±–æ–ª–µ–µ 10% –≤ –æ–¥–Ω—É –ø–æ–∑–∏—Ü–∏—é
    STOP_LOSS = 0.08  # –°—Ç–æ–ø-–ª–æ—Å—Å 8%

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è API
    MAX_REQUESTS_PER_MINUTE = 30
    REQUEST_TIMEOUT = 30
    RETRY_ATTEMPTS = 3

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
    MIN_TRAINING_SAMPLES = 100
    MIN_HISTORY_DAYS = 252  # 1 –≥–æ–¥ –¥–∞–Ω–Ω—ã—Ö
    WALK_FORWARD_WINDOW = 63  # 3 –º–µ—Å—è—Ü–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏


# ==================== –ö–õ–ê–°–° –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –û–®–ò–ë–û–ö ====================
class ErrorHandler:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ —Å –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

    @staticmethod
    def handle_data_error(func):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏"""

        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except pd.errors.EmptyDataError as e:
                logger.error(f"–ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ {func.__name__}: {e}")
                return None
            except pd.errors.ParserError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ {func.__name__}: {e}")
                return None
            except ValueError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π –≤ {func.__name__}: {e}")
                return None
            except Exception as e:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ {func.__name__}: {e}")
                return None

        return wrapper

    @staticmethod
    def handle_network_error(func):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–æ–∫"""

        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(SecurityConfig.RETRY_ATTEMPTS):
                try:
                    return func(*args, **kwargs)
                except requests.exceptions.Timeout as e:
                    logger.warning(f"–¢–∞–π–º–∞—É—Ç –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1} –≤ {func.__name__}: {e}")
                    if attempt == SecurityConfig.RETRY_ATTEMPTS - 1:
                        logger.error(f"–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Ç–∞–π–º–∞—É—Ç–∞ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –≤ {func.__name__}")
                        return None
                    time.sleep(2 ** attempt)  # Exponential backoff
                except requests.exceptions.ConnectionError as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1} –≤ {func.__name__}: {e}")
                    if attempt == SecurityConfig.RETRY_ATTEMPTS - 1:
                        logger.error(f"–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏—Å—á–µ—Ä–ø–∞–Ω—ã –≤ {func.__name__}")
                        return None
                    time.sleep(2 ** attempt)
                except requests.exceptions.RequestException as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ {func.__name__}: {e}")
                    return None
                except Exception as e:
                    logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Å–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –≤ {func.__name__}: {e}")
                    return None

        return wrapper

    @staticmethod
    def handle_model_error(func):
        """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ ML –º–æ–¥–µ–ª–µ–π"""

        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except ValueError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏ –≤ {func.__name__}: {e}")
                return None
            except AttributeError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞—Ç—Ä–∏–±—É—Ç–∞ –º–æ–¥–µ–ª–∏ –≤ {func.__name__}: {e}")
                return None
            except Exception as e:
                logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ –≤ {func.__name__}: {e}")
                return None

        return wrapper


# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –î–ê–ù–ù–´–• ====================
RUSSIAN_SECTORS = {
    '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['GAZP', 'LKOH', 'ROSN', 'SNGS', 'TATN'],
    '–ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π': ['ALRS', 'CHMK', 'MTLR', 'TRNFP'],
    '–ë–∞–∑–æ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã': ['GMKN', 'NLMK', 'MAGN', 'PLZL', 'RUAL'],
    '–†–æ–∑–Ω–∏—á–Ω–∞—è –∏ –æ–ø—Ç–æ–≤–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è': ['FIVE', 'DSKY', 'LNTA', 'OZON'],
    '–ú–µ–¥–∏—Ü–∏–Ω–∞, —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç–∏–∫–∞, –æ—Ö—Ä–∞–Ω–∞ –∑–¥–æ—Ä–æ–≤—å—è': ['POLY', 'RGSS', 'YNDX'],
    '–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π': ['GCHE', 'UPRO', 'WUSH'],
    '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏': ['MTSS', 'RTKM', 'MGNT'],
    '–•–∏–º–∏—è –∏ –Ω–µ—Ñ—Ç–µ—Ö–∏–º–∏—è': ['PHOR', 'AKRN', 'ODVA'],
    '–≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['FEES', 'HYDR', 'IRAO'],
    '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ': ['PIKK', 'LSRG', 'UNAC'],
    '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': ['AFLT', 'NMTP', 'TRMK']
}

RUSSIAN_FEEDS = {
    "–í–µ–¥–æ–º–æ—Å—Ç–∏": "https://www.vedomosti.ru/rss/news",
    "–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç": "https://www.kommersant.ru/RSS/news.xml",
    "–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å": "https://www.interfax.ru/rss.asp",
    "–¢–ê–°–°": "https://tass.ru/rss/v2.xml",
    "–õ–µ–Ω—Ç–∞.—Ä—É": "https://lenta.ru/rss/news"
}


# ==================== –£–õ–£–ß–®–ï–ù–ù–´–ô –ö–õ–ê–°–° –ò–ò –ú–û–î–ï–õ–ò –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö ====================
class EnhancedStockAIModel:
    def __init__(self, model_path='enhanced_stock_ai_model_v2.joblib'):
        self.model_path = model_path
        self.model = None
        self.probabilistic_model = None
        self.advanced_model = None
        self.scaler = RobustScaler()
        self.imputer = SimpleImputer(strategy='median')
        self.feature_selector = None
        self.is_trained = False
        self.training_history = []
        self.model_metadata = {}
        self.logger = logger
        self.benchmark_returns = {}

        self._initialize_model_with_validation()

    def _initialize_model_with_validation(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –¥–∞–Ω–Ω—ã—Ö"""
        self.logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–ò –º–æ–¥–µ–ª–µ–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π...")

        if not self._try_load_existing_model():
            self.logger.info("üìù –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
            self._create_new_models_with_validation()

    def _try_load_existing_model(self):
        """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        try:
            if not os.path.exists(self.model_path):
                self.logger.warning("–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                return False

            model_data = joblib.load(self.model_path)
            return self._validate_and_load_model(model_data)

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def _validate_and_load_model(self, model_data):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        try:
            required_keys = ['main_model', 'probabilistic_model', 'advanced_model',
                             'scaler', 'imputer', 'model_metadata']

            missing_keys = [key for key in required_keys if key not in model_data]
            if missing_keys:
                self.logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª—é—á–∏ –≤ –º–æ–¥–µ–ª–∏: {missing_keys}")
                return False

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏
            metadata = model_data.get('model_metadata', {})
            if metadata.get('model_type') != 'EnhancedStockAIModel_v2':
                self.logger.warning("–£—Å—Ç–∞—Ä–µ–≤—à–∞—è –≤–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é")
                return False

            self.model = model_data['main_model']
            self.probabilistic_model = model_data['probabilistic_model']
            self.advanced_model = model_data['advanced_model']
            self.scaler = model_data['scaler']
            self.imputer = model_data['imputer']
            self.is_trained = model_data.get('is_trained', False)
            self.training_history = model_data.get('training_history', [])
            self.model_metadata = metadata

            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—É—á–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
            if self.is_trained and self.model_metadata.get('total_training_samples',
                                                           0) < SecurityConfig.MIN_TRAINING_SAMPLES:
                self.logger.warning("–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö")
                self.is_trained = False

            self.logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–∞")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def _create_new_models_with_validation(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            self.model = RandomForestRegressor(
                n_estimators=200,
                max_depth=15,
                min_samples_split=10,
                min_samples_leaf=4,
                max_features='sqrt',
                random_state=42,
                n_jobs=-1,
                verbose=0
            )

            # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å
            self.probabilistic_model = BayesianRidge(
                n_iter=300,
                tol=1e-4,
                alpha_1=1e-6,
                alpha_2=1e-6,
                lambda_1=1e-6,
                lambda_2=1e-6
            )

            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
            self.advanced_model = GradientBoostingRegressor(
                n_estimators=200,
                max_depth=8,
                learning_rate=0.05,
                subsample=0.8,
                random_state=42,
                verbose=0
            )

            self.imputer = SimpleImputer(strategy='median')
            self.scaler = RobustScaler()

            self.is_trained = False
            self.model_metadata = {
                'creation_date': datetime.now().isoformat(),
                'total_training_samples': 0,
                'training_sessions': 0,
                'last_training': None,
                'model_type': 'EnhancedStockAIModel_v2',
                'feature_count': 0,
                'validation_score': 0.0
            }

            self.logger.info("‚úÖ –ù–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ —Å–æ–∑–¥–∞–Ω—ã —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –ø—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏
            self.model = RandomForestRegressor(n_estimators=50, random_state=42)
            self.probabilistic_model = BayesianRidge()
            self.advanced_model = GradientBoostingRegressor(n_estimators=50, random_state=42)
            self.is_trained = False

    @ErrorHandler.handle_data_error
    def _validate_features(self, features_dict):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if not features_dict:
            self.logger.warning("–ü—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            return {}

        validated_features = {}
        validation_errors = []

        for ticker, features in features_dict.items():
            try:
                if not features:
                    validation_errors.append(f"–ü—É—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {ticker}")
                    continue

                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy array
                feature_array = np.array(list(features.values()), dtype=np.float64)

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
                if np.any(np.isnan(feature_array)):
                    validation_errors.append(f"NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ {ticker}")
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏
                if np.any(np.isinf(feature_array)):
                    validation_errors.append(f"–ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ {ticker}")
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω—É–ª–µ–≤—É—é –¥–∏—Å–ø–µ—Ä—Å–∏—é
                if np.std(feature_array) < 1e-8:
                    validation_errors.append(f"–ù—É–ª–µ–≤–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è –≤ {ticker}")
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã–±—Ä–æ—Å—ã (3 sigma rule)
                z_scores = np.abs((feature_array - np.mean(feature_array)) / np.std(feature_array))
                if np.any(z_scores > 5):
                    self.logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤—ã–±—Ä–æ—Å—ã –≤ {ticker}, –Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")

                validated_features[ticker] = features

            except (ValueError, TypeError) as e:
                validation_errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è {ticker}: {e}")
                continue

        if validation_errors:
            self.logger.warning(f"–ü—Ä–æ–±–ª–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {validation_errors[:5]}")  # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫

        self.logger.info(f"‚úÖ –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ {len(validated_features)} –∏–∑ {len(features_dict)} –Ω–∞–±–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return validated_features

    @ErrorHandler.handle_data_error
    def calculate_technical_indicators(self, price_series):
        """–†–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        if price_series is None or len(price_series) < 50:  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
            self.logger.warning(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {len(price_series) if price_series else 0} —Ç–æ—á–µ–∫")
            return {}

        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if price_series.isna().any():
                self.logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –≤ —Ü–µ–Ω–æ–≤–æ–π —Å–µ—Ä–∏–∏, –∑–∞–ø–æ–ª–Ω—è–µ–º...")
                price_series = price_series.ffill().bfill()

            if (price_series <= 0).any():
                self.logger.error("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω—ã")
                return {}

            returns = price_series.pct_change().dropna()
            if len(returns) < 20:
                return {}

            # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω—ã–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
            windows = [5, 20, 50, 100]
            sma_values = {}
            for window in windows:
                if len(price_series) >= window:
                    sma = price_series.rolling(window).mean()
                    sma_values[f'sma_{window}'] = sma.iloc[-1] if not sma.isna().iloc[-1] else price_series.iloc[-1]
                else:
                    sma_values[f'sma_{window}'] = price_series.iloc[-1]

            # RSI —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π edge cases
            delta = price_series.diff()
            gain = (delta.where(delta > 0, 0)).rolling(14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()

            # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
            rs = np.where(loss != 0, gain / loss, 1.0)
            rsi = 100 - (100 / (1 + rs))
            rsi_value = rsi.iloc[-1] if not pd.isna(rsi.iloc[-1]) else 50.0

            # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏
            volatility_short = returns.tail(20).std() if len(returns) >= 20 else 0.02
            volatility_medium = returns.tail(50).std() if len(returns) >= 50 else volatility_short
            volatility_long = returns.std() if len(returns) >= 100 else volatility_medium

            # –ú–æ–º–µ–Ω—Ç—É–º —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
            periods = [22, 66, 132]  # 1, 3, 6 –º–µ—Å—è—Ü–µ–≤
            momentum_values = {}
            for period in periods:
                if len(price_series) > period:
                    prev_price = price_series.iloc[-period - 1]
                    if prev_price > 0:
                        momentum_values[f'momentum_{period}'] = (price_series.iloc[-1] / prev_price - 1)
                    else:
                        momentum_values[f'momentum_{period}'] = 0.0
                else:
                    momentum_values[f'momentum_{period}'] = 0.0

            # MACD
            if len(price_series) >= 26:
                ema_12 = price_series.ewm(span=12).mean()
                ema_26 = price_series.ewm(span=26).mean()
                macd = ema_12 - ema_26
                macd_signal = macd.ewm(span=9).mean()
                macd_histogram = macd - macd_signal
                macd_value = macd_histogram.iloc[-1] if not pd.isna(macd_histogram.iloc[-1]) else 0.0
            else:
                macd_value = 0.0

            # –°–±–æ—Ä –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            indicators = {
                'sma_ratio_5_20': sma_values['sma_5'] / sma_values['sma_20'] if sma_values['sma_20'] != 0 else 1.0,
                'sma_ratio_20_50': sma_values['sma_20'] / sma_values['sma_50'] if sma_values['sma_50'] != 0 else 1.0,
                'sma_ratio_50_100': sma_values['sma_50'] / sma_values['sma_100'] if sma_values['sma_100'] != 0 else 1.0,
                'price_vs_sma20': price_series.iloc[-1] / sma_values['sma_20'] if sma_values['sma_20'] != 0 else 1.0,
                'rsi': float(rsi_value),
                'volatility_ratio_short': volatility_short / volatility_long if volatility_long != 0 else 1.0,
                'volatility_ratio_medium': volatility_medium / volatility_long if volatility_long != 0 else 1.0,
                'macd_histogram': float(macd_value),
                'volatility': float(volatility_long),
                'current_price': float(price_series.iloc[-1])
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–º–µ–Ω—Ç—É–º
            indicators.update({k: float(v) for k, v in momentum_values.items()})

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
            for key, value in indicators.items():
                if np.isnan(value) or np.isinf(value):
                    self.logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ {key}: {value}")
                    return {}

            return indicators

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
            return {}

    @ErrorHandler.handle_data_error
    def create_advanced_features(self, prices_df, news_sentiment):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        if prices_df is None or prices_df.empty:
            self.logger.error("–ü—É—Å—Ç–æ–π DataFrame —Ü–µ–Ω")
            return {}

        features = {}
        successful_features = 0
        failed_features = 0

        for ticker in prices_df.columns:
            try:
                if ticker not in prices_df:
                    failed_features += 1
                    continue

                price_series = prices_df[ticker].dropna()
                if len(price_series) < 50:  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ
                    failed_features += 1
                    continue

                # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                technical_features = self.calculate_technical_indicators(price_series)
                if not technical_features:
                    failed_features += 1
                    continue

                # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                sector = self.get_sector_for_ticker(ticker)
                sector_sentiment = news_sentiment.get(sector, 0)

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                price_stats = {
                    'price_range_20': (price_series.tail(20).max() - price_series.tail(20).min()) / price_series.tail(
                        20).mean(),
                    'volume_profile': price_series.rolling(20).std().iloc[
                                          -1] / price_series.mean() if price_series.mean() != 0 else 0,
                    'trend_strength': self._calculate_trend_strength(price_series)
                }

                feature_set = {
                    **technical_features,
                    **price_stats,
                    'sector_sentiment': float(sector_sentiment),
                    'days_of_data': len(price_series)
                }

                features[ticker] = feature_set
                successful_features += 1

            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {ticker}: {e}")
                failed_features += 1
                continue

        self.logger.info(f"üìä –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {successful_features} —É—Å–ø–µ—à–Ω–æ, {failed_features} –Ω–µ—É–¥–∞—á–Ω–æ")

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        validated_features = self._validate_features(features)
        return validated_features

    def _calculate_trend_strength(self, price_series):
        """–†–∞—Å—á–µ—Ç —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞"""
        if len(price_series) < 20:
            return 0.0

        try:
            # Linear regression –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞
            x = np.arange(len(price_series)).reshape(-1, 1)
            y = price_series.values.reshape(-1, 1)

            from sklearn.linear_model import LinearRegression
            reg = LinearRegression().fit(x, y)
            trend_slope = reg.coef_[0][0]
            r_squared = reg.score(x, y)

            return float(trend_slope * r_squared)
        except:
            return 0.0

    @ErrorHandler.handle_data_error
    def prepare_training_data(self, prices_df, news_sentiment_by_date, forecast_days=10):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        self.logger.info("üìã –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")

        if prices_df is None or prices_df.empty:
            self.logger.error("‚ùå –ü—É—Å—Ç–æ–π DataFrame —Ü–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return np.array([]), np.array([]), np.array([]), np.array([])

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if prices_df.isna().any().any():
            self.logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –≤ —Ü–µ–Ω–∞—Ö, –∑–∞–ø–æ–ª–Ω—è–µ–º...")
            prices_df = prices_df.ffill().bfill()
            # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å –æ—Å—Ç–∞–≤—à–∏–º–∏—Å—è NaN
            prices_df = prices_df.dropna(axis=1, how='any')

        if prices_df.empty:
            self.logger.error("‚ùå DataFrame —Å—Ç–∞–ª –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ NaN")
            return np.array([]), np.array([]), np.array([]), np.array([])

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
        current_sentiment = {}
        if news_sentiment_by_date:
            try:
                latest_date = max(news_sentiment_by_date.keys())
                current_sentiment = news_sentiment_by_date[latest_date]
            except Exception as e:
                self.logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞: {e}")

        features_dict = self.create_advanced_features(prices_df, current_sentiment)

        if not features_dict:
            self.logger.error("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return np.array([]), np.array([]), np.array([]), np.array([])

        X_basic, X_advanced, y_basic, y_advanced = [], [], [], []
        successful_targets = 0
        failed_targets = 0

        for ticker, features in features_dict.items():
            try:
                if not features or len(features) == 0:
                    failed_targets += 1
                    continue

                if ticker not in prices_df.columns:
                    failed_targets += 1
                    continue

                price_series = prices_df[ticker].dropna()
                if len(price_series) <= forecast_days:
                    failed_targets += 1
                    continue

                # –†–ï–ê–õ–¨–ù–ê–Ø —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è - –±—É–¥—É—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
                current_price = price_series.iloc[-1]
                future_idx = -forecast_days - 1

                if len(price_series) > abs(future_idx):
                    future_price = price_series.iloc[future_idx]

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ —Ü–µ–Ω
                    if current_price <= 0 or future_price <= 0:
                        failed_targets += 1
                        continue

                    actual_return = (current_price / future_price - 1)

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
                    if abs(actual_return) > 2.0:  # –§–∏–ª—å—Ç—Ä —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                        self.logger.warning(f"–≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –¥–ª—è {ticker}: {actual_return:.3f}")
                        failed_targets += 1
                        continue

                    feature_vector = list(features.values())

                    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ feature vector
                    if (len(feature_vector) == len(features) and
                            not any(np.isnan(feature_vector)) and
                            not any(np.isinf(feature_vector)) and
                            not np.isnan(actual_return)):

                        X_basic.append(feature_vector)
                        X_advanced.append(feature_vector)
                        y_basic.append(actual_return)
                        y_advanced.append(actual_return)
                        successful_targets += 1
                    else:
                        failed_targets += 1
                else:
                    failed_targets += 1

            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker}: {e}")
                failed_targets += 1
                continue

        self.logger.info(f"üéØ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ —Ü–µ–ª–µ–π: {successful_targets} —É—Å–ø–µ—à–Ω–æ, {failed_targets} –Ω–µ—É–¥–∞—á–Ω–æ")

        if successful_targets < SecurityConfig.MIN_TRAINING_SAMPLES:
            self.logger.warning(
                f"‚ö†Ô∏è –ú–∞–ª–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {successful_targets} < {SecurityConfig.MIN_TRAINING_SAMPLES}")
            return np.array([]), np.array([]), np.array([]), np.array([])

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ numpy arrays —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        try:
            X_basic_array = np.array(X_basic, dtype=np.float64)
            X_advanced_array = np.array(X_advanced, dtype=np.float64)
            y_basic_array = np.array(y_basic, dtype=np.float64)
            y_advanced_array = np.array(y_advanced, dtype=np.float64)

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            if (X_basic_array.shape[0] == y_basic_array.shape[0] == successful_targets and
                    X_advanced_array.shape[0] == y_advanced_array.shape[0] == successful_targets):

                self.logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã: {X_basic_array.shape} features, {successful_targets} samples")
                return X_basic_array, X_advanced_array, y_basic_array, y_advanced_array
            else:
                self.logger.error("‚ùå –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –¥–∞–Ω–Ω—ã—Ö")
                return np.array([]), np.array([]), np.array([]), np.array([])

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ numpy: {e}")
            return np.array([]), np.array([]), np.array([]), np.array([])

    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∞ —Å –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ ...

    @ErrorHandler.handle_model_error
    def train_models(self, prices_df, news_sentiment_by_date, incremental=True):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        self.logger.info("üîÑ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")

        try:
            if self.model is None:
                self._create_new_models_with_validation()

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            X_basic, X_advanced, y_basic, y_advanced = self.prepare_training_data(
                prices_df, news_sentiment_by_date
            )

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
            if len(X_basic) < SecurityConfig.MIN_TRAINING_SAMPLES:
                self.logger.error(
                    f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(X_basic)} < {SecurityConfig.MIN_TRAINING_SAMPLES}")
                return False

            self.logger.info(f"üéØ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(X_basic)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö...")

            # Walk-forward validation
            tscv = TimeSeriesSplit(n_splits=5)
            validation_scores = []

            for train_idx, test_idx in tscv.split(X_basic):
                try:
                    X_train, X_test = X_basic[train_idx], X_basic[test_idx]
                    y_train, y_test = y_basic[train_idx], y_basic[test_idx]

                    # –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞
                    self.model.fit(X_train, y_train)
                    y_pred = self.model.predict(X_test)
                    score = mean_squared_error(y_test, y_pred)
                    validation_scores.append(score)

                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –≤ fold –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
                    continue

            if validation_scores:
                avg_score = np.mean(validation_scores)
                self.model_metadata['validation_score'] = avg_score
                self.logger.info(f"üìä –°—Ä–µ–¥–Ω—è—è MSE –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {avg_score:.6f}")

            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
            try:
                X_processed = self._safe_fit_transform(X_basic, incremental)
                X_advanced_processed = self._safe_fit_transform(X_advanced, incremental)

                if self.is_trained and incremental:
                    self.logger.info("üìö –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
                    self.model.fit(X_processed, y_basic)
                    self.probabilistic_model.fit(X_processed, y_basic)
                    self.advanced_model.fit(X_advanced_processed, y_advanced)
                else:
                    self.logger.info("üéì –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
                    self.model.fit(X_processed, y_basic)
                    self.probabilistic_model.fit(X_processed, y_basic)
                    self.advanced_model.fit(X_advanced_processed, y_advanced)

            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
                return False

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            self.is_trained = True
            self._update_training_metadata(len(X_basic))
            self.model_metadata['feature_count'] = X_basic.shape[1] if len(X_basic.shape) > 1 else 0

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            if not self._save_models():
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª–∏")
                return False

            avg_return = np.mean(y_advanced) if len(y_advanced) > 0 else 0
            self.logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {avg_return:.4f}")
            return True

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            traceback.print_exc()
            return False

    def _safe_fit_transform(self, X, incremental=False):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        if len(X) == 0:
            return X

        try:
            # –ó–∞–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è NaN —á–µ—Ä–µ–∑ –∏–º–ø—å—é—Ç–µ—Ä
            if not self.is_trained or not incremental:
                X_imputed = self.imputer.fit_transform(X)
            else:
                X_imputed = self.imputer.transform(X)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–º–ø—å—é—Ç–∞—Ü–∏–∏
            if np.any(np.isnan(X_imputed)):
                self.logger.warning("NaN –æ—Å—Ç–∞–ª–∏—Å—å –ø–æ—Å–ª–µ –∏–º–ø—å—é—Ç–∞—Ü–∏–∏, –ø—Ä–∏–º–µ–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É")
                X_imputed = np.nan_to_num(X_imputed, nan=0.0)

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            if not self.is_trained or not incremental:
                X_scaled = self.scaler.fit_transform(X_imputed)
            else:
                X_scaled = self.scaler.transform(X_imputed)

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            if np.any(np.isnan(X_scaled)) or np.any(np.isinf(X_scaled)):
                self.logger.error("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN/Inf –ø–æ—Å–ª–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è")
                return X_imputed  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –Ω–æ –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

            return X_scaled

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return X  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏


# ==================== –ö–õ–ê–°–° –†–ò–°–ö-–ú–ï–ù–ï–î–ñ–ú–ï–ù–¢–ê ====================
class RiskManager:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Ä–∏—Å–∫–æ–≤ —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""

    def __init__(self):
        self.max_drawdown = SecurityConfig.MAX_DRAWDOWN
        self.sector_limits = SecurityConfig.SECTOR_LIMITS
        self.position_sizing = SecurityConfig.POSITION_SIZING
        self.stop_loss = SecurityConfig.STOP_LOSS
        self.risk_free_rate = 0.05  # 5% –±–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞
        self.logger = logger

    def validate_portfolio_weights(self, weights, prices_df, current_positions=None):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Å–æ–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å —É—á–µ—Ç–æ–º —Ä–∏—Å–∫–æ–≤"""
        if not weights:
            self.logger.warning("–ü—É—Å—Ç—ã–µ –≤–µ—Å–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è")
            return {}

        validated_weights = {}
        total_weight = 0
        sector_exposure = {}

        for ticker, weight in weights.items():
            try:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–∏–∫–µ—Ä–∞
                if ticker not in prices_df.columns:
                    self.logger.warning(f"–¢–∏–∫–µ—Ä {ticker} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –ø–æ–∑–∏—Ü–∏–∏
                if weight > self.position_sizing:
                    self.logger.warning(f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è {ticker}: {weight:.3f} > {self.position_sizing}")
                    weight = self.position_sizing

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –≤–µ—Å–∞
                if weight < 0:
                    self.logger.warning(f"–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –≤–µ—Å –¥–ª—è {ticker}: {weight:.3f}")
                    continue

                # –†–∞—Å—á–µ—Ç —ç–∫—Å–ø–æ–∑–∏—Ü–∏–∏ –ø–æ —Å–µ–∫—Ç–æ—Ä–∞–º
                sector = self._get_sector_for_ticker(ticker)
                sector_exposure[sector] = sector_exposure.get(sector, 0) + weight

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ —Å–µ–∫—Ç–æ—Ä–∞
                if sector_exposure[sector] > self.sector_limits:
                    self.logger.warning(
                        f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —Å–µ–∫—Ç–æ—Ä–∞ {sector}: {sector_exposure[sector]:.3f} > {self.sector_limits}")
                    available_weight = self.sector_limits - (sector_exposure[sector] - weight)
                    weight = min(weight, available_weight)

                if weight > 0:
                    validated_weights[ticker] = weight
                    total_weight += weight

            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤–µ—Å–∞ –¥–ª—è {ticker}: {e}")
                continue

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        if total_weight > 0:
            validated_weights = {k: v / total_weight for k, v in validated_weights.items()}
            self.logger.info(f"‚úÖ –í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã –≤–µ—Å–∞ –¥–ª—è {len(validated_weights)} –∞–∫—Ç–∏–≤–æ–≤")
        else:
            self.logger.warning("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –≤–µ—Å–æ–≤ –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∏—Å–∫–æ–≤")

        return validated_weights

    def _get_sector_for_ticker(self, ticker):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–µ–∫—Ç–æ—Ä–∞ –¥–ª—è —Ç–∏–∫–µ—Ä–∞"""
        for sector, tickers in RUSSIAN_SECTORS.items():
            if ticker in tickers:
                return sector
        return '–û–±—â–∏–µ'


# ==================== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –°–ò–°–¢–ï–ú–´ –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö ====================
class EnhancedStockAnalysisSystem:
    def __init__(self):
        self.logger = logger
        self.news_collector = NewsCollector()
        self.stock_collector = StockDataCollector()
        self.news_analyzer = NewsAnalyzer()
        self.enhanced_ai_model = EnhancedStockAIModel()
        self.portfolio = VirtualPortfolio()
        self.web_interface = WebInterface()
        self.risk_manager = RiskManager()

        self.news_backup_file = 'news_backup.csv'
        self.prices_backup_file = 'prices_backup.csv'
        self.recommendations_file = 'RECOM.csv'

        self.setup_system()

    def setup_system(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            self._check_dependencies()

            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
            self._create_directories()

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            self._initialize_components()

            self.logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã: {e}")
            raise

    def _check_dependencies(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
        required_libraries = [
            'pandas', 'numpy', 'sklearn', 'requests',
            'feedparser', 'flask', 'joblib', 'scipy'
        ]

        missing_libraries = []
        for lib in required_libraries:
            try:
                __import__(lib)
            except ImportError:
                missing_libraries.append(lib)

        if missing_libraries:
            error_msg = f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {', '.join(missing_libraries)}"
            self.logger.error(error_msg)
            raise ImportError(error_msg)

    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
        directories = ['data', 'models', 'logs', 'backups']
        for directory in directories:
            try:
                os.makedirs(directory, exist_ok=True)
            except Exception as e:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é {directory}: {e}")

    def _initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
        if not self.enhanced_ai_model.is_trained:
            self.logger.warning("–ú–æ–¥–µ–ª—å –ò–ò –Ω–µ –æ–±—É—á–µ–Ω–∞, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ")

    @ErrorHandler.handle_network_error
    def run_enhanced_analysis_cycle(self):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ —Å –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        self.logger.info("\n" + "=" * 60)
        self.logger.info(f"üîç –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("=" * 60)

        try:
            # 1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
            self.logger.info("üì∞ –®–∞–≥ 1: –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π...")
            news_df = self.news_collector.fetch_all_news()
            if news_df is None or news_df.empty:
                self.logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ")
                news_df = self._load_backup_news()

            # 2. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ü–∏—è—Ö
            self.logger.info("üìä –®–∞–≥ 2: –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ü–∏—è—Ö...")
            all_tickers = [ticker for sector_tickers in RUSSIAN_SECTORS.values() for ticker in sector_tickers]
            prices_df = self.stock_collector.get_stock_prices(all_tickers, days=252)  # 1 –≥–æ–¥ –¥–∞–Ω–Ω—ã—Ö

            if prices_df is None or prices_df.empty:
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–± –∞–∫—Ü–∏—è—Ö")
                return False

            # 3. –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π
            self.logger.info("üîç –®–∞–≥ 3: –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π...")
            news_recommendations = self.news_analyzer.predict_sector_sentiment(news_df)

            # 4. –û–±—É—á–µ–Ω–∏–µ AI –º–æ–¥–µ–ª–µ–π
            self.logger.info("üéØ –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ AI –º–æ–¥–µ–ª–µ–π...")
            news_sentiment_by_date = {datetime.now().date(): news_recommendations}

            training_successful = self.enhanced_ai_model.train_models(
                prices_df, news_sentiment_by_date, incremental=True
            )

            if not training_successful:
                self.logger.warning("–û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

            # 5. AI –∞–Ω–∞–ª–∏–∑ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
            self.logger.info("üß† –®–∞–≥ 5: AI –∞–Ω–∞–ª–∏–∑ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è...")
            current_prices = prices_df.iloc[-1].to_dict()

            optimal_weights = {}
            if self.enhanced_ai_model.is_trained:
                ai_predictions = self.enhanced_ai_model.predict_returns(prices_df, news_recommendations)
                optimal_weights = self.enhanced_ai_model.optimize_portfolio(ai_predictions, prices_df)

                # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Å–æ–≤ —á–µ—Ä–µ–∑ risk manager
                optimal_weights = self.risk_manager.validate_portfolio_weights(
                    optimal_weights, prices_df, self.portfolio.positions
                )

            # 6. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            enhanced_recommendations = self._enhance_recommendations_with_optimization(
                news_recommendations, optimal_weights
            )

            # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            portfolio_value = self.portfolio.get_portfolio_value(current_prices)
            self.save_backup_data(news_df, prices_df, enhanced_recommendations)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
            model_info = self.enhanced_ai_model.get_model_status()
            self.web_interface.update_data(
                enhanced_recommendations, news_df, portfolio_value, optimal_weights, model_info
            )

            # 8. –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._print_enhanced_results(enhanced_recommendations, optimal_weights, portfolio_value)

            return True

        except Exception as e:
            self.logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            traceback.print_exc()
            return False

    def _load_backup_news(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        try:
            if os.path.exists(self.news_backup_file):
                return pd.read_csv(self.news_backup_file)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return pd.DataFrame()

    def run_continuous_analysis(self, interval_minutes=3):
        """–ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–±–æ–µ–≤"""
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π —Å –ò–ò...")

        # –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–∏—Å–∫–ª–µ–π–º–µ—Ä
        self._print_legal_disclaimer()

        try:
            # –ó–∞–ø—É—Å–∫ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            web_thread = threading.Thread(target=self.web_interface.run_server)
            web_thread.daemon = True
            web_thread.start()

            cycle_count = 0
            consecutive_failures = 0
            max_consecutive_failures = 3

            while self.web_interface.is_running and consecutive_failures < max_consecutive_failures:
                try:
                    success = self.run_enhanced_analysis_cycle()
                    cycle_count += 1

                    if success:
                        consecutive_failures = 0
                        self.logger.info(f"‚ôªÔ∏è –¶–∏–∫–ª {cycle_count} –∑–∞–≤–µ—Ä—à–µ–Ω. –û–∂–∏–¥–∞–Ω–∏–µ {interval_minutes} –º–∏–Ω—É—Ç...")

                        # –û–∂–∏–¥–∞–Ω–∏–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ñ–ª–∞–≥–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                        wait_seconds = interval_minutes * 60
                        for i in range(wait_seconds):
                            if not self.web_interface.is_running:
                                break
                            time.sleep(1)
                    else:
                        consecutive_failures += 1
                        self.logger.error(
                            f"‚ùå –û—à–∏–±–∫–∞ —Ü–∏–∫–ª–∞ {cycle_count}. –ü–æ–ø—ã—Ç–∫–∞ {consecutive_failures}/{max_consecutive_failures}")
                        time.sleep(300)  # 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ

                except KeyboardInterrupt:
                    self.logger.info("‚ö†Ô∏è –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                    break
                except Exception as e:
                    consecutive_failures += 1
                    self.logger.error(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                    time.sleep(300)

            if consecutive_failures >= max_consecutive_failures:
                self.logger.error("üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã")

        except Exception as e:
            self.logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å–∏—Å—Ç–µ–º—ã: {e}")
        finally:
            self.logger.info("üõë –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

    def _print_legal_disclaimer(self):
        """–í—ã–≤–æ–¥ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–≥–æ –¥–∏—Å–∫–ª–µ–π–º–µ—Ä–∞"""
        disclaimer = """
        ‚ö†Ô∏è –Æ–†–ò–î–ò–ß–ï–°–ö–û–ï –£–í–ï–î–û–ú–õ–ï–ù–ò–ï –ò –û–¢–ö–ê–ó –û–¢ –û–¢–í–ï–¢–°–¢–í–ï–ù–ù–û–°–¢–ò

       
        """
        print(disclaimer)
        self.logger.info("–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –¥–∏—Å–∫–ª–µ–π–º–µ—Ä –æ—Ç–æ–±—Ä–∞–∂–µ–Ω")


# ==================== –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´ ====================
if __name__ == "__main__":
    try:
        system = EnhancedStockAnalysisSystem()
        system.run_continuous_analysis(interval_minutes=3)
    except Exception as e:
        logger.critical(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–∏—Å—Ç–µ–º—ã: {e}")
        sys.exit(1)