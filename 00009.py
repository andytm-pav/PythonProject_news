import os
import sys
import time
import requests
import feedparser
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from tqdm import tqdm
import warnings
import joblib
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import re

warnings.filterwarnings('ignore')

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø RSS-–õ–ï–ù–¢ ====================
RUSSIAN_FEEDS = {
    "–í–µ–¥–æ–º–æ—Å—Ç–∏": "https://www.vedomosti.ru/rss/news",
    "–ö–æ–º–º–µ—Ä—Å–∞–Ω—Ç": "https://www.kommersant.ru/RSS/news.xml",
    "–ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å": "https://www.interfax.ru/rss.asp",
    "–¢–ê–°–°": "https://tass.ru/rss/v2.xml",
    "–õ–µ–Ω—Ç–∞.—Ä—É": "https://lenta.ru/rss/news",
    "–§–∏–Ω–∞–º": "https://www.finam.ru/analysis/conews/rsspoint/",
    "–ë–§–ú": "https://www.bfm.ru/news.rss",
    "–ò–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ": "https://ru.investing.com/rss/news_25.rss"
}

# ==================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–ï–ö–¢–û–†–û–í –ò –ê–ö–¶–ò–ô ====================
RUSSIAN_SECTORS = {
    '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['GAZP', 'LKOH', 'ROSN', 'SNGS', 'TATN'],
    '–ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π': ['FLOT', 'NMTP', 'TRMK', 'KMAZ'],
    '–ë–∞–∑–æ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã': ['GMKN', 'NLMK', 'MAGN', 'PLZL', 'RUAL'],
    '–†–æ–∑–Ω–∏—á–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è': ['MGNT', 'FIVE', 'DSKY', 'LNTA'],
    '–ú–µ–¥–∏—Ü–∏–Ω–∞': ['PHOR', 'POLY', 'RGSS'],
    '–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π': ['BELU', 'WTCM', 'UPRO'],
    '–¢–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏': ['MTSS', 'RTKM', 'MFON'],
    '–•–∏–º–∏—è': ['HIMC', 'KAZT'],
    '–≠–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['FEES', 'HYDR', 'IRAO', 'TGKA'],
    '–°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ': ['PIKK', 'LSRG', 'UNAC'],
    '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç': ['AFLT', 'NKHP']
}


# ==================== –§–£–ù–ö–¶–ò–Ø –°–ë–û–†–ê –ù–û–í–û–°–¢–ï–ô –° –ü–†–û–í–ï–†–ö–ê–ú–ò ====================
def fetch_russian_feeds_safe(feeds_dict, max_items_per_feed=10):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å RSS-–ª–µ–Ω—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    if not feeds_dict:
        print("‚ùå –°–ª–æ–≤–∞—Ä—å RSS-–ª–µ–Ω—Ç –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
        return pd.DataFrame()

    rows = []

    for name, url in tqdm(feeds_dict.items(), desc="–°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π"):
        try:
            feed = feedparser.parse(url)
            time.sleep(1)

            if not hasattr(feed, 'entries') or not feed.entries:
                continue

            for entry in feed.entries[:max_items_per_feed]:
                title = getattr(entry, 'title', '').strip()
                if title:
                    rows.append({
                        'source': name,
                        'title': title,
                        'link': getattr(entry, 'link', ''),
                        'published': getattr(entry, 'published', ''),
                        'summary': getattr(entry, 'summary', '')[:200]
                    })

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {name}: {e}")
            continue

    if not rows:
        print("‚ö†Ô∏è –ù–µ —Å–æ–±—Ä–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏, —Å–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
        return create_sample_news_data()

    df = pd.DataFrame(rows)
    df = df.drop_duplicates(subset=['title'])
    df['published'] = pd.to_datetime(df['published'], errors='coerce')
    df = df.dropna(subset=['published'])

    print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(df)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    return df


def create_sample_news_data():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"""
    sample_titles = [
        "–ê–∫—Ü–∏–∏ –ì–∞–∑–ø—Ä–æ–º–∞ —Ä–∞—Å—Ç—É—Ç –Ω–∞ —Ñ–æ–Ω–µ —Ä–æ—Å—Ç–∞ —Ü–µ–Ω –Ω–∞ –Ω–µ—Ñ—Ç—å",
        "–°–±–µ—Ä–±–∞–Ω–∫ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –¥–∏–≤–∏–¥–µ–Ω–¥—ã –ø–æ –∏—Ç–æ–≥–∞–º –≥–æ–¥–∞",
        "–†–æ—Å—Å–∏–π—Å–∫–∏–π —Ä—ã–Ω–æ–∫ –∞–∫—Ü–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç",
        "–ö–æ–º–ø–∞–Ω–∏–∏ –º–µ—Ç–∞–ª–ª—É—Ä–≥–∏—á–µ—Å–∫–æ–≥–æ —Å–µ–∫—Ç–æ—Ä–∞ —É–≤–µ–ª–∏—á–∏–≤–∞—é—Ç –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ",
        "–ò–Ω–≤–µ—Å—Ç–æ—Ä—ã –ø—Ä–æ—è–≤–ª—è—é—Ç –∏–Ω—Ç–µ—Ä–µ—Å –∫ –∞–∫—Ü–∏—è–º IT-—Å–µ–∫—Ç–æ—Ä–∞"
    ]

    data = []
    for i, title in enumerate(sample_titles):
        data.append({
            'source': '—Ç–µ—Å—Ç',
            'title': title,
            'link': '',
            'published': datetime.now() - timedelta(hours=i),
            'summary': '',
            'index': i
        })

    return pd.DataFrame(data)


# ==================== –§–£–ù–ö–¶–ò–Ø –ü–û–õ–£–ß–ï–ù–ò–Ø –¶–ï–ù –ê–ö–¶–ò–ô –° –ü–†–û–í–ï–†–ö–ê–ú–ò ====================
def get_russian_stock_prices_safe(tickers, days=30):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ü–µ–Ω –∞–∫—Ü–∏–π"""
    try:
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å MOEX
        # –°–µ–π—á–∞—Å —Å–æ–∑–¥–∞–¥–∏–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ

        dates = pd.date_range(end=datetime.now(), periods=days, freq='D')
        prices_df = pd.DataFrame(index=dates)

        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–Ω—ã –¥–ª—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∞–∫—Ü–∏–π
        base_prices = {
            'SBER': 250, 'GAZP': 160, 'LKOH': 5800, 'GMKN': 25000,
            'NLMK': 180, 'MTSS': 270, 'ROSN': 420, 'TATN': 380
        }

        for ticker in tickers:
            if ticker in base_prices:
                base_price = base_prices[ticker]
                returns = np.random.normal(0.001, 0.02, days)
                prices = [base_price]
                for ret in returns[1:]:
                    prices.append(prices[-1] * (1 + ret))
                prices_df[ticker] = prices

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(prices_df.columns)} —Ç–∏–∫–µ—Ä–æ–≤")
        return prices_df

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None


# ==================== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê ====================
class NewsAnalyzer:
    def __init__(self):
        self.sector_keywords = self._build_sector_keywords()

    def _build_sector_keywords(self):
        return {
            '–≠–Ω–µ—Ä–≥–µ—Ç–∏–∫–∞': ['–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '–Ω–µ—Ñ—Ç–µ–≥–∞–∑', '—ç–Ω–µ—Ä–≥–µ—Ç–∏–∫'],
            '–ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π': ['—Ñ–∏–Ω–∞–Ω—Å', '–±–∞–Ω–∫', '–∏–Ω–≤–µ—Å—Ç', '–∫—Ä–µ–¥–∏—Ç'],
            # ... –¥–æ–±–∞–≤—å—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –≤—Å–µ—Ö —Å–µ–∫—Ç–æ—Ä–æ–≤
        }

    def predict_sector_movement(self, news_df):
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –¥–≤–∏–∂–µ–Ω–∏—è —Å–µ–∫—Ç–æ—Ä–æ–≤"""
        recommendations = {}
        for sector in RUSSIAN_SECTORS.keys():
            # –ë–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ - –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à—É
            recommendations[sector] = np.random.randint(-2, 3)
        return recommendations


# ==================== –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö ====================
def main():
    print("=== –°–ò–°–¢–ï–ú–ê –ê–ù–ê–õ–ò–ó–ê –†–û–°–°–ò–ô–°–ö–û–ì–û –†–´–ù–ö–ê –ê–ö–¶–ò–ô ===")

    analyzer = NewsAnalyzer()
    iteration = 0

    while True:
        try:
            print(f"\nüîÑ –ò—Ç–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ #{iteration + 1}")

            # 1. –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            print("üì∞ –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π...")
            news_df = fetch_russian_feeds_safe(RUSSIAN_FEEDS)

            if news_df.empty:
                print("‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞—é –∏—Ç–µ—Ä–∞—Ü–∏—é")
                time.sleep(60)
                continue

            # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ü–∏—è—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–± –∞–∫—Ü–∏—è—Ö...")
            all_tickers = []
            for sector_tickers in RUSSIAN_SECTORS.values():
                all_tickers.extend(sector_tickers)

            prices_data = get_russian_stock_prices_safe(all_tickers)

            # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ None –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
            if prices_data is None:
                print("‚ùå –î–∞–Ω–Ω—ã–µ –æ–± –∞–∫—Ü–∏—è—Ö –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞—é –∏—Ç–µ—Ä–∞—Ü–∏—é")
                time.sleep(60)
                continue

            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º iterrows
            if not hasattr(prices_data, 'iterrows'):
                print("‚ùå –û–±—ä–µ–∫—Ç prices_data –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç iterrows")
                time.sleep(60)
                continue

            # 4. –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ iterrows
            try:
                for index, row in prices_data.iterrows():
                    # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
                    pass
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ iterrows: {e}")

            # 5. –ê–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            print("üîç –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π...")
            recommendations = analyzer.predict_sector_movement(news_df)

            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            save_recommendations(recommendations)

            print("‚úÖ –ò—Ç–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            iteration += 1
            time.sleep(300)  # –ü–∞—É–∑–∞ 5 –º–∏–Ω—É—Ç

        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            break
        except Exception as e:
            print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            time.sleep(60)


def save_recommendations(recommendations, filename='RECOM.csv'):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ CSV"""
    try:
        df = pd.DataFrame(list(recommendations.items()),
                          columns=['–°–µ–∫—Ç–æ—Ä', '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è'])
        df['–í—Ä–µ–º–µ–Ω–Ω–∞—è_–º–µ—Ç–∫–∞'] = datetime.now()
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"üíæ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")


if __name__ == "__main__":
    main()